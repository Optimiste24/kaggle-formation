{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "48394592-d479-428d-af01-34dead85b2a0",
   "metadata": {},
   "source": [
    "# Cours : Écrire des Requêtes Efficaces\n",
    "\n",
    "**Écrivez des requêtes qui s'exécutent plus rapidement et utilisent moins de données.**\n",
    "\n",
    "## Introduction\n",
    "Parfois, l'efficacité de votre requête n'a pas d'importance. Par exemple, vous pourriez écrire une requête que vous prévoyez d'exécuter une seule fois, et elle pourrait fonctionner sur un petit ensemble de données. Dans ce cas, tout ce qui vous donne la réponse dont vous avez besoin fera l'affaire.\n",
    "\n",
    "Mais qu'en est-il des requêtes qui seront exécutées plusieurs fois, comme une requête qui alimente un site web en données ? Ces requêtes doivent être efficaces pour ne pas laisser les utilisateurs attendre que votre site se charge.\n",
    "\n",
    "Ou encore, qu'en est-il des requêtes sur des ensembles de données volumineux ? Celles-ci peuvent être lentes et coûter cher à une entreprise si elles sont mal écrites.\n",
    "\n",
    "La plupart des systèmes de bases de données disposent d'un optimiseur de requêtes qui tente d'interpréter/exécuter votre requête de la manière la plus efficace possible. Cependant, plusieurs stratégies peuvent encore permettre d'économiser considérablement des ressources dans de nombreux cas.\n",
    "\n",
    "#### Quelques fonctions utiles\n",
    "Nous allons utiliser deux fonctions pour comparer l'efficacité de différentes requêtes :\n",
    "\n",
    "- `show_amount_of_data_scanned()` montre la quantité de données utilisée par la requête.\n",
    "- `show_time_to_run()` affiche le temps qu'il faut pour exécuter la requête.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "524b4040-1643-4460-bb2b-bbcf9c8d826f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import bigquery\n",
    "from time import time\n",
    "\n",
    "client = bigquery.Client()\n",
    "\n",
    "def show_amount_of_data_scanned(query):\n",
    "    # dry_run permet de voir la quantité de données utilisée par la requête sans l'exécuter\n",
    "    dry_run_config = bigquery.QueryJobConfig(dry_run=True)\n",
    "    query_job = client.query(query, job_config=dry_run_config)\n",
    "    print('Données traitées : {} Go'.format(round(query_job.total_bytes_processed / 10**9, 3)))\n",
    "    \n",
    "def show_time_to_run(query):\n",
    "    time_config = bigquery.QueryJobConfig(use_query_cache=False)\n",
    "    start = time()\n",
    "    query_result = client.query(query, job_config=time_config).result()\n",
    "    end = time()\n",
    "    print('Temps d\\'exécution : {} secondes'.format(round(end-start, 3)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a4e1fdd-7aa7-4813-9b40-7db508043f70",
   "metadata": {},
   "source": [
    "---\n",
    "## Stratégies\n",
    "\n",
    "**1) Sélectionnez uniquement les colonnes dont vous avez besoin.**\n",
    "Il est tentant de commencer les requêtes par `SELECT * FROM ...`. C'est pratique car vous n'avez pas besoin de réfléchir aux colonnes dont vous avez besoin. Mais cela peut être très inefficace.\n",
    "\n",
    "C'est particulièrement important s'il y a des champs texte dont vous n'avez pas besoin, car les champs texte ont tendance à être plus volumineux que les autres champs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dad3d411-b00c-410c-99a6-09fa14d0d0bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Données traitées : 2682.118 Go\n",
      "Données traitées : 2.531 Go\n"
     ]
    }
   ],
   "source": [
    "star_query = \"SELECT * FROM `bigquery-public-data.github_repos.contents`\"\n",
    "show_amount_of_data_scanned(star_query)\n",
    "\n",
    "basic_query = \"SELECT size, binary FROM `bigquery-public-data.github_repos.contents`\"\n",
    "show_amount_of_data_scanned(basic_query)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "194fab5a-487a-4506-97d8-f43962000c9c",
   "metadata": {},
   "source": [
    "Dans ce cas, nous observons une réduction de 1000X des données analysées pour exécuter la requête, car les données brutes contenaient un champ texte est 1000X plus volumineux que les champs dont nous avions besoin.\n",
    "\n",
    "---\n",
    "**2) Lisez moins de données.**\n",
    "\n",
    "Les deux requêtes ci-dessous calculent la durée moyenne (en secondes) des trajets à vélo à sens unique dans la ville de San Francisco.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "42382257-67f3-434f-8424-38c81ffeeca4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Données traitées : 0.076 Go\n",
      "Données traitées : 0.06 Go\n"
     ]
    }
   ],
   "source": [
    "more_data_query = \"\"\"\n",
    "                  SELECT MIN(start_station_name) AS start_station_name,\n",
    "                      MIN(end_station_name) AS end_station_name,\n",
    "                      AVG(duration_sec) AS avg_duration_sec\n",
    "                  FROM `bigquery-public-data.san_francisco.bikeshare_trips`\n",
    "                  WHERE start_station_id != end_station_id \n",
    "                  GROUP BY start_station_id, end_station_id\n",
    "                  LIMIT 10\n",
    "                  \"\"\"\n",
    "show_amount_of_data_scanned(more_data_query)\n",
    "\n",
    "less_data_query = \"\"\"\n",
    "                  SELECT start_station_name,\n",
    "                      end_station_name,\n",
    "                      AVG(duration_sec) AS avg_duration_sec                  \n",
    "                  FROM `bigquery-public-data.san_francisco.bikeshare_trips`\n",
    "                  WHERE start_station_name != end_station_name\n",
    "                  GROUP BY start_station_name, end_station_name\n",
    "                  LIMIT 10\n",
    "                  \"\"\"\n",
    "show_amount_of_data_scanned(less_data_query)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41eef101-2826-4e4a-8df6-79189ed0f305",
   "metadata": {},
   "source": [
    "Comme il existe une relation **1:1** entre l'ID de la station et le nom de la station, nous n'avons pas besoin d'utiliser les colonnes `start_station_id` et `end_station_id` dans la requête. En utilisant uniquement les colonnes avec les noms des stations, nous analysons moins de données.\n",
    "\n",
    "---\n",
    "**3) Évitez les JOIN N:N.**\n",
    "\n",
    "La plupart des JOIN que vous avez exécutés dans ce cours étaient des JOIN **1:1**. Dans ce cas, chaque ligne d'une table correspond au plus à une ligne dans l'autre table.\n",
    "\n",
    "Un autre type de JOIN est le JOIN **N:1**. Ici, chaque ligne d'une table peut correspondre à plusieurs lignes dans l'autre table.\n",
    "\n",
    "Enfin, un JOIN **N:N** est un JOIN où un groupe de lignes dans une table peut correspondre à un groupe de lignes dans l'autre table. Notez que, toutes choses égales par ailleurs, ce type de JOIN produit une table avec beaucoup plus de lignes que les deux tables d'origine qui sont jointes.\n",
    "\n",
    "Maintenant, nous allons travailler avec un exemple tiré d'un jeu de données réel. Les deux exemples ci-dessous comptent le nombre de contributeurs distincts et le nombre de fichiers dans plusieurs dépôts GitHub.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a942ce00-f2d5-434b-a0d1-6e2adeeec7ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Temps d'exécution : 18.169 secondes\n",
      "Temps d'exécution : 3.272 secondes\n"
     ]
    }
   ],
   "source": [
    "big_join_query = \"\"\"\n",
    "                 SELECT repo,\n",
    "                     COUNT(DISTINCT c.committer.name) as num_committers,\n",
    "                     COUNT(DISTINCT f.id) AS num_files\n",
    "                 FROM `bigquery-public-data.github_repos.commits` AS c,\n",
    "                     UNNEST(c.repo_name) AS repo\n",
    "                 INNER JOIN `bigquery-public-data.github_repos.files` AS f\n",
    "                     ON f.repo_name = repo\n",
    "                 WHERE f.repo_name IN ( 'tensorflow/tensorflow', 'facebook/react', 'twbs/bootstrap', 'apple/swift', 'Microsoft/vscode', 'torvalds/linux')\n",
    "                 GROUP BY repo\n",
    "                 ORDER BY repo\n",
    "                 \"\"\"\n",
    "show_time_to_run(big_join_query)\n",
    "\n",
    "small_join_query = \"\"\"\n",
    "                   WITH commits AS\n",
    "                   (\n",
    "                   SELECT COUNT(DISTINCT committer.name) AS num_committers, repo\n",
    "                   FROM `bigquery-public-data.github_repos.commits`,\n",
    "                       UNNEST(repo_name) as repo\n",
    "                   WHERE repo IN ( 'tensorflow/tensorflow', 'facebook/react', 'twbs/bootstrap', 'apple/swift', 'Microsoft/vscode', 'torvalds/linux')\n",
    "                   GROUP BY repo\n",
    "                   ),\n",
    "                   files AS \n",
    "                   (\n",
    "                   SELECT COUNT(DISTINCT id) AS num_files, repo_name as repo\n",
    "                   FROM `bigquery-public-data.github_repos.files`\n",
    "                   WHERE repo_name IN ( 'tensorflow/tensorflow', 'facebook/react', 'twbs/bootstrap', 'apple/swift', 'Microsoft/vscode', 'torvalds/linux')\n",
    "                   GROUP BY repo\n",
    "                   )\n",
    "                   SELECT commits.repo, commits.num_committers, files.num_files\n",
    "                   FROM commits \n",
    "                   INNER JOIN files\n",
    "                       ON commits.repo = files.repo\n",
    "                   ORDER BY repo\n",
    "                   \"\"\"\n",
    "\n",
    "show_time_to_run(small_join_query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbe7212f-13a1-4e55-bc59-b1345376aebe",
   "metadata": {},
   "source": [
    "La première requête contient un JOIN N:N volumineux. En réécrivant la requête pour réduire la taille du JOIN, nous constatons qu'elle s'exécute beaucoup plus rapidement.\n",
    "\n",
    "#### Pour en savoir plus\n",
    "Ces stratégies et bien d'autres sont discutées dans ce guide complet sur Google BigQuery. Si vous souhaitez en savoir plus sur la manière d'écrire des requêtes plus efficaces (ou approfondir vos connaissances sur tout ce qui concerne BigQuery), nous vous encourageons à le consulter !\n",
    "\n",
    "#### À vous de jouer\n",
    "Utilisez ce que vous avez appris pour améliorer la conception de plusieurs requêtes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf515d26-69cf-4fcc-bdb5-39d3747816ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "33b5345a-602a-4249-a64c-0355dde75bce",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# **EXERCICE**\n",
    "\n",
    "### Introduction  \n",
    "Vous allez maintenant utiliser ce que vous avez appris dans le tutoriel précédent pour améliorer l'efficacité de plusieurs requêtes.  \n",
    "\n",
    "Avant de commencer, exécutez la cellule suivante pour tout configurer.  \n",
    "\n",
    "```python\n",
    "# Configuration du système de feedback  \n",
    "from learntools.core import binder  \n",
    "binder.bind(globals())  \n",
    "from learntools.sql_advanced.ex4 import *  \n",
    "print(\"Configuration terminée\")  \n",
    "```  \n",
    "\n",
    "---  \n",
    "\n",
    "### Question 1) Vous travaillez pour **Pet Costumes International**  \n",
    "\n",
    "Vous devez écrire trois requêtes cet après-midi. Vous avez assez de temps pour rédiger des versions fonctionnelles des trois, mais seulement le temps d'optimiser l'une d'entre elles. Laquelle de ces requêtes mérite le plus d'être optimisée ?  \n",
    "\n",
    "- Un ingénieur logiciel a développé une application pour le **service d'expédition**, afin de voir quels articles doivent être expédiés et dans quelle allée de l'entrepôt ils se trouvent. Il vous demande d'écrire la requête. Celle-ci impliquera des données stockées dans les tables `orders`, `shipments` et `warehouseLocation`. Les employés utiliseront cette application sur une tablette, actualiseront la page, et votre requête affichera les résultats en temps réel pour leur montrer quels costumes envoyer et où.  \n",
    "\n",
    "- Le **PDG** souhaite obtenir une liste de tous les avis clients et des réclamations… qui sont stockés dans une seule table `reviews`. Certains avis sont très longs… car les gens adorent vos costumes de pirates pour perroquets et n’arrêtent pas d’écrire à quel point ils sont adorables.  \n",
    "\n",
    "- Les **propriétaires de chiens** deviennent de plus en plus protecteurs. Votre département d’ingénierie a donc conçu des costumes équipés de **GPS et de dispositifs de communication sans fil**. Ces costumes envoient leurs coordonnées à votre base de données **chaque seconde**. Vous avez un site web où les propriétaires peuvent localiser leurs chiens (ou du moins, les costumes qu’ils portent). Pour que ce service fonctionne, vous avez besoin d'une requête qui affiche la **position la plus récente de tous les costumes appartenant à un humain donné**. Cette requête impliquera les tables `CostumeLocations` et `CostumeOwners`.  \n",
    "\n",
    "### Question :  \n",
    "Laquelle de ces requêtes bénéficierait le plus d'une **optimisation** ?  \n",
    "Définissez la variable `query_to_optimize` avec la valeur **1, 2 ou 3** (de type `integer`)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e7ead02-384d-4ee2-8a75-592bbe31f951",
   "metadata": {},
   "source": [
    "Correct :  \n",
    "\n",
    "# Remplissez votre réponse\n",
    "query_to_optimize = 3  # La requête 3 est la plus critique car elle traite des données en temps réel.\n",
    "\n",
    "**Pourquoi 3 ?** Parce que des données sont envoyées pour chaque costume chaque seconde, cette requête est probablement celle qui traite le plus de données (de loin). De plus, elle sera exécutée de manière récurrente. L’optimiser peut donc avoir un impact significatif sur les performances.  \n",
    "\n",
    "**Pourquoi pas 1 ?** C'est la deuxième requête la plus intéressante à optimiser. Elle sera exécutée régulièrement et implique des jointures, ce qui est souvent un point clé pour améliorer l’efficacité des requêtes.  \n",
    "\n",
    "**Pourquoi pas 2 ?** Cette requête ne semble être exécutée qu’une seule fois. Il importe donc peu qu’elle prenne quelques secondes de plus ou qu’elle coûte légèrement plus cher à exécuter. De plus, elle n’implique pas de jointures. Bien que les données contiennent des champs texte (les avis), ce sont des informations nécessaires à la requête. Il n’est donc pas possible d’en exclure certaines pour économiser des ressources de calcul."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bc1a3db-4dde-4410-a4a8-1a090c9a9229",
   "metadata": {},
   "source": [
    "---\n",
    "### Question 2) Faciliter la recherche de Mitzie !\n",
    "\n",
    "Vous disposez des deux tables suivantes :  \n",
    "\n",
    "*(Image)*  \n",
    "\n",
    "La table **CostumeLocations** contient des données GPS horodatées pour tous les costumes pour animaux enregistrés dans la base de données. La colonne **CostumeID** est un identifiant unique pour chaque costume.  \n",
    "\n",
    "La table **CostumeOwners** indique qui possède chaque costume. La colonne **OwnerID** contient des identifiants uniques pour chaque propriétaire (humain). Notez que :  \n",
    "- Chaque propriétaire peut avoir plusieurs costumes.  \n",
    "- Chaque costume peut être associé à plusieurs propriétaires, ce qui permet à plusieurs membres d’un même foyer (ayant chacun leur propre **OwnerID**) d’accéder aux informations de localisation des costumes de leurs animaux.  \n",
    "\n",
    "Supposons que vous deviez utiliser ces tables pour retrouver l’emplacement actuel d’un animal en particulier : **Mitzie le chien** s'est récemment enfui en poursuivant un écureuil, mais heureusement, il a été vu pour la dernière fois portant son **costume de hot-dog** !  \n",
    "\n",
    "L’un des propriétaires de Mitzie (dont l’identifiant est **MitzieOwnerID**) se connecte à votre site pour récupérer les dernières localisations de **tous les costumes qu'il possède**. Actuellement, cette information est obtenue via la requête suivante :  \n",
    "\n",
    "```sql\n",
    "WITH LocationsAndOwners AS \n",
    "(\n",
    "    SELECT *  \n",
    "    FROM CostumeOwners co  \n",
    "    INNER JOIN CostumeLocations cl  \n",
    "        ON co.CostumeID = cl.CostumeID\n",
    "),\n",
    "LastSeen AS \n",
    "(\n",
    "    SELECT CostumeID, MAX(Timestamp)  \n",
    "    FROM LocationsAndOwners  \n",
    "    GROUP BY CostumeID\n",
    ")\n",
    "SELECT lo.CostumeID, Location  \n",
    "FROM LocationsAndOwners lo  \n",
    "INNER JOIN LastSeen ls  \n",
    "    ON lo.Timestamp = ls.Timestamp  \n",
    "    AND lo.CostumeID = ls.CostumeID  \n",
    "WHERE OwnerID = MitzieOwnerID\n",
    "```\n",
    "\n",
    "**Peut-on rendre cette requête plus rapide ou moins coûteuse ?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "017557c2-8169-4f7d-9593-032039908e12",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "aaa9a9b7-5ade-4c64-995f-cc7f2b30a7f4",
   "metadata": {},
   "source": [
    "Oui, il est possible d'optimiser cette requête pour qu'elle soit plus rapide et moins coûteuse. Voici quelques améliorations possibles :  \n",
    "\n",
    "### **1. Éviter la CTE inutile**  \n",
    "L’utilisation de la CTE `LocationsAndOwners` (**Common Table Expression**) entraîne la jointure de toutes les données de **CostumeOwners** et **CostumeLocations** avant même de filtrer par `MitzieOwnerID`. Cela crée une table temporaire inutilement volumineuse.  \n",
    "\n",
    "🔹 **Amélioration** :  \n",
    "- Filtrer **dès le départ** sur `OwnerID = MitzieOwnerID` pour éviter de manipuler des millions de lignes inutilement.  \n",
    "\n",
    "### **2. Optimiser la récupération de la dernière position**  \n",
    "L’utilisation de `MAX(Timestamp)` dans une CTE intermédiaire (LastSeen) oblige à faire un `GROUP BY`, ce qui peut être coûteux en ressources.  \n",
    "\n",
    "🔹 **Amélioration** :  \n",
    "- Utiliser `ORDER BY Timestamp DESC` avec `LIMIT 1` pour chaque costume. Cela permet d’éviter une agrégation lourde et de récupérer directement la dernière ligne enregistrée.  \n",
    "\n",
    "### **3. Éviter le `SELECT *`**  \n",
    "Faire `SELECT *` dans la CTE signifie que l'on récupère **toutes les colonnes**, même celles qui ne sont pas utilisées dans le résultat final.  \n",
    "\n",
    "🔹 **Amélioration** :  \n",
    "- Sélectionner uniquement les colonnes nécessaires : `CostumeID`, `Timestamp`, `Location`, et `OwnerID`.  \n",
    "\n",
    "---\n",
    "\n",
    "### **Requête optimisée** :  \n",
    "\n",
    "```sql\n",
    "WITH LastSeen AS (\n",
    "    SELECT cl.CostumeID, cl.Location, cl.Timestamp \n",
    "    FROM CostumeLocations cl\n",
    "    JOIN CostumeOwners co ON cl.CostumeID = co.CostumeID\n",
    "    WHERE co.OwnerID = MitzieOwnerID\n",
    "    ORDER BY cl.Timestamp DESC\n",
    "    LIMIT 1\n",
    ")\n",
    "SELECT CostumeID, Location\n",
    "FROM LastSeen;\n",
    "```\n",
    "\n",
    "### **Pourquoi cette requête est plus efficace ?**  \n",
    "✅ Elle filtre dès le départ sur **MitzieOwnerID**, réduisant le volume de données traitées.  \n",
    "✅ Elle **évite le GROUP BY** et utilise `ORDER BY ... LIMIT 1`, qui est plus rapide.  \n",
    "✅ Elle ne récupère que les **colonnes nécessaires**, évitant un surplus de données en mémoire.  \n",
    "\n",
    "💡 **Résultat** : Cette version est bien plus rapide et consomme moins de ressources, ce qui la rend plus scalable ! 🚀"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35455261-d6be-45a4-8de6-2121a5f690c5",
   "metadata": {},
   "source": [
    "---\n",
    "### **Traduction du corrigé :**  \n",
    "\n",
    "**Solution :** Oui. Travailler avec la table `LocationsAndOwners` est très inefficace, car c'est une table volumineuse. Il existe plusieurs options pour améliorer cela, et la meilleure dépend des spécificités de la base de données. Une amélioration probable est la suivante :  \n",
    "\n",
    "```sql\n",
    "WITH CurrentOwnersCostumes AS\n",
    "(\n",
    "    SELECT CostumeID \n",
    "    FROM CostumeOwners \n",
    "    WHERE OwnerID = MitzieOwnerID\n",
    "),\n",
    "OwnersCostumesLocations AS\n",
    "(\n",
    "    SELECT cc.CostumeID, Timestamp, Location \n",
    "    FROM CurrentOwnersCostumes cc \n",
    "    INNER JOIN CostumeLocations cl ON cc.CostumeID = cl.CostumeID\n",
    "),\n",
    "LastSeen AS\n",
    "(\n",
    "    SELECT CostumeID, MAX(Timestamp)\n",
    "    FROM OwnersCostumesLocations\n",
    "    GROUP BY CostumeID\n",
    ")\n",
    "SELECT ocl.CostumeID, Location \n",
    "FROM OwnersCostumesLocations ocl \n",
    "INNER JOIN LastSeen ls \n",
    "    ON ocl.timestamp = ls.timestamp \n",
    "    AND ocl.CostumeID = ls.CostumeID;\n",
    "```\n",
    "\n",
    "### **Pourquoi cette version est-elle meilleure ?**  \n",
    "\n",
    "Au lieu d'effectuer des **jointures volumineuses** et d'exécuter des calculs (comme la recherche du dernier `timestamp`) pour **tous les costumes**, on élimine dès le début les lignes correspondant aux autres propriétaires.  \n",
    "\n",
    "Ainsi, chaque étape suivante (comme le calcul du dernier `timestamp`) travaille sur **beaucoup moins de données**. Concrètement, on réduit le nombre de lignes traitées d’environ **99,999 %** par rapport à la requête initiale.  \n",
    "\n",
    "Les bases de données disposent de **\"Query Planners\"** (planificateurs de requêtes) qui optimisent automatiquement certains détails d'exécution, même après l'écriture de la requête. Cependant, la requête originale, telle qu'elle était écrite, serait **très inefficace** sur de grands ensembles de données.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08c6f192-98e1-434f-bdab-764cd1801312",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
