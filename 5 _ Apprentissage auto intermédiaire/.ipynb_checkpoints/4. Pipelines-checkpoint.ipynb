{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0dea2769-def1-44d5-8708-a2080eb1aae5",
   "metadata": {},
   "source": [
    "# Pipelines\n",
    "Une compétence essentielle pour déployer (et même tester) des modèles complexes avec prétraitement."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "febaf995-a8a3-417a-8be2-8d30f148635f",
   "metadata": {},
   "source": [
    "Dans ce tutoriel, vous apprendrez à utiliser les pipelines pour simplifier votre code de modélisation.\n",
    "\n",
    "## Introduction\n",
    "Les pipelines sont un moyen simple d'organiser votre code de prétraitement des données et de modélisation. Concrètement, un pipeline regroupe les étapes de prétraitement et de modélisation, de sorte que vous puissiez utiliser l'ensemble comme une seule étape.\n",
    "\n",
    "De nombreux **data scientists** créent des modèles sans pipelines, mais les pipelines offrent d'importants avantages :\n",
    "\n",
    "- **Code plus propre** : Gérer les données à chaque étape de prétraitement peut devenir compliqué. Avec un pipeline, vous n'aurez pas besoin de suivre manuellement vos données d'entraînement et de validation à chaque étape.\n",
    "- **Moins de bugs** : Il y a moins de risques d'appliquer une étape de manière incorrecte ou d'oublier une étape de prétraitement.\n",
    "- **Facilité de mise en production** : Passer d'un prototype à un modèle déployable à grande échelle peut être étonnamment difficile. Bien que nous n'abordions pas tous les aspects connexes ici, les pipelines peuvent faciliter cette transition.\n",
    "- **Plus d'options pour la validation des modèles** : Vous verrez un exemple dans le prochain tutoriel, qui couvre la validation croisée."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b4bd72e-02f8-41fc-968a-c97323931304",
   "metadata": {},
   "source": [
    "### Exemple\n",
    "Comme dans le tutoriel précédent, nous travaillerons avec le jeu de données sur le logement à Melbourne.\n",
    "\n",
    "Nous ne nous concentrerons pas sur l'étape de chargement des données. Imaginez que vous avez déjà les données d'entraînement et de validation dans `X_train` , `X_valid` , `y_train` et `y_valid`.\n",
    "\n",
    "Nous jetons un coup d'œil aux données d'entraînement avec la méthode head(). \n",
    "\n",
    "Remarquez que les données contiennent à la fois des données catégoriques et des colonnes avec des valeurs manquantes. Avec un pipeline, il est facile de traiter les deux !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6160673d-fc87-449c-acaf-b1a8ffa94b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Charger les données\n",
    "melbourne_file_path = 'melb_data.csv'\n",
    "melbourne_data = pd.read_csv(melbourne_file_path)\n",
    "\n",
    "# Identifier les colonnes numériques et catégoriques\n",
    "numerical_cols = X_train.select_dtypes(include=['int64', 'float64']).columns\n",
    "categorical_cols = X_train.select_dtypes(include=['object']).columns\n",
    "\n",
    "# Variables catégorielles à conserver\n",
    "keep_cols = ['Type', 'Method', 'Regionname']\n",
    "\n",
    "# Supprimer les autres variables catégorielles\n",
    "melbourne_data = melbourne_data.drop(columns=[col for col in categorical_cols if col not in keep_cols])\n",
    "\n",
    "# Supprimer les lignes avec une cible manquante, séparer la cible des prédicteurs\n",
    "melbourne_data.dropna(axis=0, subset=['Price'], inplace=True)\n",
    "y = melbourne_data.Price\n",
    "X = melbourne_data.drop(['Price'], axis=1)  # Retirez inplace=True\n",
    "\n",
    "# Diviser en données d'entraînement et de validation\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, train_size=0.8, test_size=0.2, random_state=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4cba1a05-6540-49d8-ac8a-df739965955c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Suburb</th>\n",
       "      <th>Address</th>\n",
       "      <th>Rooms</th>\n",
       "      <th>Type</th>\n",
       "      <th>Method</th>\n",
       "      <th>SellerG</th>\n",
       "      <th>Date</th>\n",
       "      <th>Distance</th>\n",
       "      <th>Postcode</th>\n",
       "      <th>Bedroom2</th>\n",
       "      <th>Bathroom</th>\n",
       "      <th>Car</th>\n",
       "      <th>Landsize</th>\n",
       "      <th>BuildingArea</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>CouncilArea</th>\n",
       "      <th>Lattitude</th>\n",
       "      <th>Longtitude</th>\n",
       "      <th>Regionname</th>\n",
       "      <th>Propertycount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12167</th>\n",
       "      <td>St Kilda</td>\n",
       "      <td>11/22 Charnwood Cr</td>\n",
       "      <td>1</td>\n",
       "      <td>u</td>\n",
       "      <td>S</td>\n",
       "      <td>hockingstuart</td>\n",
       "      <td>29/07/2017</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3182.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1940.0</td>\n",
       "      <td>Port Phillip</td>\n",
       "      <td>-37.85984</td>\n",
       "      <td>144.9867</td>\n",
       "      <td>Southern Metropolitan</td>\n",
       "      <td>13240.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6524</th>\n",
       "      <td>Williamstown</td>\n",
       "      <td>18 James St</td>\n",
       "      <td>2</td>\n",
       "      <td>h</td>\n",
       "      <td>SA</td>\n",
       "      <td>Hunter</td>\n",
       "      <td>17/09/2016</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3016.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>193.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hobsons Bay</td>\n",
       "      <td>-37.85800</td>\n",
       "      <td>144.9005</td>\n",
       "      <td>Western Metropolitan</td>\n",
       "      <td>6380.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8413</th>\n",
       "      <td>Sunshine</td>\n",
       "      <td>10 Dundalk St</td>\n",
       "      <td>3</td>\n",
       "      <td>h</td>\n",
       "      <td>S</td>\n",
       "      <td>Barry</td>\n",
       "      <td>8/04/2017</td>\n",
       "      <td>12.6</td>\n",
       "      <td>3020.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>555.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Brimbank</td>\n",
       "      <td>-37.79880</td>\n",
       "      <td>144.8220</td>\n",
       "      <td>Western Metropolitan</td>\n",
       "      <td>3755.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2919</th>\n",
       "      <td>Glenroy</td>\n",
       "      <td>1/2 Prospect St</td>\n",
       "      <td>3</td>\n",
       "      <td>u</td>\n",
       "      <td>SP</td>\n",
       "      <td>Brad</td>\n",
       "      <td>18/06/2016</td>\n",
       "      <td>13.0</td>\n",
       "      <td>3046.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>265.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1995.0</td>\n",
       "      <td>Moreland</td>\n",
       "      <td>-37.70830</td>\n",
       "      <td>144.9158</td>\n",
       "      <td>Northern Metropolitan</td>\n",
       "      <td>8870.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6043</th>\n",
       "      <td>Sunshine North</td>\n",
       "      <td>35 Furlong Rd</td>\n",
       "      <td>3</td>\n",
       "      <td>h</td>\n",
       "      <td>S</td>\n",
       "      <td>First</td>\n",
       "      <td>22/05/2016</td>\n",
       "      <td>13.3</td>\n",
       "      <td>3020.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>673.0</td>\n",
       "      <td>673.0</td>\n",
       "      <td>1970.0</td>\n",
       "      <td>Brimbank</td>\n",
       "      <td>-37.76230</td>\n",
       "      <td>144.8272</td>\n",
       "      <td>Western Metropolitan</td>\n",
       "      <td>4217.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Suburb             Address  Rooms Type Method        SellerG  \\\n",
       "12167        St Kilda  11/22 Charnwood Cr      1    u      S  hockingstuart   \n",
       "6524     Williamstown         18 James St      2    h     SA         Hunter   \n",
       "8413         Sunshine       10 Dundalk St      3    h      S          Barry   \n",
       "2919          Glenroy     1/2 Prospect St      3    u     SP           Brad   \n",
       "6043   Sunshine North       35 Furlong Rd      3    h      S          First   \n",
       "\n",
       "             Date  Distance  Postcode  Bedroom2  Bathroom  Car  Landsize  \\\n",
       "12167  29/07/2017       5.0    3182.0       1.0       1.0  1.0       0.0   \n",
       "6524   17/09/2016       8.0    3016.0       2.0       2.0  1.0     193.0   \n",
       "8413    8/04/2017      12.6    3020.0       3.0       1.0  1.0     555.0   \n",
       "2919   18/06/2016      13.0    3046.0       3.0       1.0  1.0     265.0   \n",
       "6043   22/05/2016      13.3    3020.0       3.0       1.0  2.0     673.0   \n",
       "\n",
       "       BuildingArea  YearBuilt   CouncilArea  Lattitude  Longtitude  \\\n",
       "12167           NaN     1940.0  Port Phillip  -37.85984    144.9867   \n",
       "6524            NaN        NaN   Hobsons Bay  -37.85800    144.9005   \n",
       "8413            NaN        NaN      Brimbank  -37.79880    144.8220   \n",
       "2919            NaN     1995.0      Moreland  -37.70830    144.9158   \n",
       "6043          673.0     1970.0      Brimbank  -37.76230    144.8272   \n",
       "\n",
       "                  Regionname  Propertycount  \n",
       "12167  Southern Metropolitan        13240.0  \n",
       "6524    Western Metropolitan         6380.0  \n",
       "8413    Western Metropolitan         3755.0  \n",
       "2919   Northern Metropolitan         8870.0  \n",
       "6043    Western Metropolitan         4217.0  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf4f5304-ad75-453a-bb45-752dea6fecba",
   "metadata": {},
   "source": [
    "Nous construisons le pipeline complet en trois étapes :\n",
    "\n",
    "---\n",
    "\n",
    "### Étape 1 : Définir les étapes de prétraitement\n",
    "Comme un pipeline regroupe les étapes de prétraitement et de modélisation, nous utilisons la classe ColumnTransformer pour regrouper différentes étapes de prétraitement. Le code ci-dessous :\n",
    "\n",
    "- Impute les valeurs manquantes dans les données numériques, et\n",
    "- Impute les valeurs manquantes et applique un encodage one-hot aux données catégoriques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2a8df1f9-aa94-4665-8eea-121b352b79af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Prétraitement des données numériques\n",
    "numerical_transformer = SimpleImputer(strategy='constant')\n",
    "\n",
    "# Prétraitement des données catégoriques\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "# Regrouper le prétraitement des données numériques et catégoriques\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_transformer, numerical_cols),\n",
    "        ('cat', categorical_transformer, categorical_cols)\n",
    "    ])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58044297-80e0-448a-88f9-94f486e22665",
   "metadata": {},
   "source": [
    "### Étape 2 : Définir le modèle\n",
    "Ensuite, nous définissons un modèle de **forêt aléatoire** avec la classe bien connue RandomForestRegressor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "baf1a653-3d9e-4a39-b7ef-776e3bcd764b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "model = RandomForestRegressor(n_estimators=100, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bc8de0c-746c-4307-b4df-52889d82faa3",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Étape 3 : Créer et évaluer le pipeline\n",
    "Enfin, nous utilisons la classe Pipeline pour définir un pipeline qui regroupe les étapes de prétraitement et de modélisation.\n",
    "\n",
    "Points importants :\n",
    "\n",
    "- Avec le pipeline, nous prétraitons les données d'entraînement et ajustons le modèle en une seule ligne de code. (Sans pipeline, il faudrait effectuer l'imputation, l'encodage one-hot et l'entraînement du modèle en étapes séparées, ce qui est particulièrement complexe avec des variables numériques et catégoriques !)\n",
    "- Avec le pipeline, nous fournissons les caractéristiques non traitées dans **X_valid** à la commande **predict()**, et le pipeline prétraite automatiquement les caractéristiques avant de générer des prédictions. (Sans pipeline, il faudrait se souvenir de prétraiter les données de validation avant de faire des prédictions.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0b3b2a1d-6e1c-463a-a2ff-bd205c31958f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 160679.18917034855\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "# Regrouper le prétraitement et la modélisation dans un pipeline\n",
    "my_pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                              ('model', model)\n",
    "                             ])\n",
    "\n",
    "# Prétraitement des données d'entraînement, ajustement du modèle\n",
    "my_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Prétraitement des données de validation, génération des prédictions\n",
    "preds = my_pipeline.predict(X_valid)\n",
    "\n",
    "# Évaluer le modèle\n",
    "score = mean_absolute_error(y_valid, preds)\n",
    "print('MAE:', score)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16cf2c87-a573-4634-8ea9-a41e77fd35ac",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Conclusion\n",
    "Les pipelines sont utiles pour organiser le code de **machine learning** et éviter les erreurs. Ils sont particulièrement précieux pour les **workflows** impliquant un prétraitement sophistiqué des données."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f870b92-5386-4c27-9e4e-d183615a8349",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
