{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "92d29e7d-e0fb-4f8c-bd08-4b865bb28779",
   "metadata": {},
   "source": [
    "# Validation croisée\n",
    "Une meilleure façon de tester vos modèles."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8924ddb4-63f2-4cb3-b2cf-cb910850ad0e",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "L'apprentissage automatique est un **processus itératif**.\n",
    "\n",
    "Vous serez confronté à des choix : quelles **variables prédictives** utiliser, quels types de modèles privilégier, quels arguments fournir à ces modèles, etc. Jusqu'à présent, vous avez pris ces décisions de manière guidée par les données, en mesurant la qualité des modèles grâce à un ensemble de validation (ou ensemble de test).\n",
    "\n",
    "Cependant, cette méthode a quelques inconvénients. Imaginez que vous avez un jeu de données avec 5000 lignes. Habituellement, vous réservez environ 20 % des données comme ensemble de validation, soit 1000 lignes. Cela laisse une part de hasard dans la détermination des scores des modèles. Par exemple, un modèle pourrait bien fonctionner sur un ensemble donné de 1000 lignes, même s'il serait peu performant sur un autre ensemble de 1000 lignes.\n",
    "\n",
    "Dans un cas extrême, imaginez que l'ensemble de validation ne contienne qu'une seule ligne. Si vous comparez des modèles, déterminer lequel prédit le mieux sur une seule donnée relèverait presque du hasard !\n",
    "\n",
    "En général, **plus l'ensemble de validation est grand, moins il y a d'aléa (ou \"bruit\") dans votre mesure de qualité des modèles, et plus celle-ci est fiable**. \n",
    "\n",
    "Malheureusement, avoir un grand ensemble de validation signifie réduire la taille des données d'entraînement, ce qui entraîne souvent des modèles moins performants.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3492a7c-6c69-4ed9-be0b-4a572babfa6c",
   "metadata": {},
   "source": [
    "## Qu'est-ce que la validation croisée ?\n",
    "La validation croisée consiste à exécuter votre processus de modélisation sur différents sous-ensembles des données pour obtenir plusieurs mesures de la qualité des modèles.\n",
    "\n",
    "Prenons un exemple : on divise les données en 5 parties, chacune représentant 20 % de l'ensemble. Ces parties sont appelées des ***\"folds\"***.\n",
    "\n",
    "**Exemple : Division en 5 folds**\n",
    "- Expérience 1 : Le premier fold est utilisé comme ensemble de validation, tandis que les autres servent à l'entraînement.\n",
    "- Expérience 2 : Le deuxième fold devient l'ensemble de validation, et les autres servent à l'entraînement.\n",
    "- Et ainsi de suite, jusqu'à ce que chaque fold ait été utilisé une fois comme ensemble de validation.\n",
    "\n",
    "Ainsi, chaque ligne des données est utilisée à un moment donné comme ensemble de validation, offrant une mesure de qualité basée sur l'ensemble complet des données (même si toutes les lignes ne sont pas utilisées simultanément).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d00ae31b-52a9-49ed-a1cf-dfc46c20c2df",
   "metadata": {},
   "source": [
    "### Quand utiliser la validation croisée ?\n",
    "La validation croisée fournit une mesure plus précise de la qualité des modèles. Cela est particulièrement important si vous prenez de nombreuses décisions concernant les modèles. Cependant, elle peut être plus longue à exécuter, car elle implique de tester plusieurs modèles (un pour chaque fold).\n",
    "\n",
    "**Recommandations** :\n",
    "- Pour les petits jeux de données, utilisez la validation croisée : la charge computationnelle supplémentaire n'est pas un problème.\n",
    "- Pour les grands jeux de données, un seul ensemble de validation est souvent suffisant, car les modèles s'entraînent plus vite et les données sont assez nombreuses pour éviter le besoin de réutiliser certaines pour le test."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d989adf0-c633-4f63-95c2-56d197d2b132",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**Exemple : Validation croisée avec Scikit-learn est fait directement sur PIPELINES**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a22f7c9a-f68a-413a-97e7-195625f58c5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Colonnes numériques : ['Rooms', 'Distance', 'Postcode', 'Bedroom2', 'Bathroom', 'Car', 'Landsize', 'BuildingArea', 'YearBuilt', 'Lattitude', 'Longtitude', 'Propertycount']\n",
      "Colonnes catégoriques : ['Type', 'Method', 'Regionname']\n",
      "Colonnes utilisées dans X_train : Index(['Rooms', 'Distance', 'Postcode', 'Bedroom2', 'Bathroom', 'Car',\n",
      "       'Landsize', 'BuildingArea', 'YearBuilt', 'Lattitude', 'Longtitude',\n",
      "       'Propertycount', 'Type', 'Method', 'Regionname'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Charger les données\n",
    "melbourne_file_path = 'melb_data.csv'\n",
    "melbourne_data = pd.read_csv(melbourne_file_path)\n",
    "\n",
    "# Supprimer les lignes avec une cible manquante et séparer la cible des prédicteurs\n",
    "melbourne_data.dropna(axis=0, subset=['Price'], inplace=True)\n",
    "y = melbourne_data['Price']\n",
    "X = melbourne_data.drop(['Price'], axis=1)\n",
    "\n",
    "# Identifier les colonnes numériques et catégoriques\n",
    "numerical_cols = X.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "categorical_cols = X.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "# Variables catégorielles à conserver\n",
    "keep_cols = ['Type', 'Method', 'Regionname']\n",
    "\n",
    "# Supprimer les variables catégoriques inutilisées\n",
    "categorical_cols = [col for col in categorical_cols if col in keep_cols]\n",
    "X = X[numerical_cols + categorical_cols]\n",
    "\n",
    "# Diviser en données d'entraînement et de validation\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, train_size=0.8, test_size=0.2, random_state=0)\n",
    "\n",
    "# Afficher les colonnes restantes\n",
    "print(\"Colonnes numériques :\", numerical_cols)\n",
    "print(\"Colonnes catégoriques :\", categorical_cols)\n",
    "print(\"Colonnes utilisées dans X_train :\", X_train.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "29574316-8094-49a4-8a4d-4152975711d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rooms              int64\n",
      "Distance         float64\n",
      "Postcode         float64\n",
      "Bedroom2         float64\n",
      "Bathroom         float64\n",
      "Car              float64\n",
      "Landsize         float64\n",
      "BuildingArea     float64\n",
      "YearBuilt        float64\n",
      "Lattitude        float64\n",
      "Longtitude       float64\n",
      "Propertycount    float64\n",
      "Type              object\n",
      "Method            object\n",
      "Regionname        object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(X.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fa78f16b-0237-41b1-9763-e4f067df0c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.select_dtypes(include=['number'])  # Garde uniquement les colonnes numériques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fe3dd992-63f4-40dd-b928-9cad00c642a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Identification des colonnes numériques et catégoriques\n",
    "numeric_features = X.select_dtypes(include=['number']).columns\n",
    "categorical_features = X.select_dtypes(exclude=['number']).columns\n",
    "\n",
    "# Transformer pour les colonnes numériques et catégoriques\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', SimpleImputer(strategy='mean'), numeric_features),  # Imputation pour colonnes numériques\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)  # Encodage pour colonnes catégoriques\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Nouveau pipeline\n",
    "my_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('model', RandomForestRegressor(n_estimators=50, random_state=0))\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6e3ce2ee-a258-46bb-a924-6d4e54f684f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores MAE :\n",
      " [215843.83846588 204063.10068764 193213.5288239  162618.89111473\n",
      " 166564.13952767]\n",
      "Score MAE moyen : 188460.6997239638\n"
     ]
    }
   ],
   "source": [
    "# Relancer la validation croisée avec le pipeline mis à jour \n",
    "scores = -1 * cross_val_score(my_pipeline, X, y, cv=5, scoring='neg_mean_absolute_error')\n",
    "print(\"Scores MAE :\\n\", scores)\n",
    "print(\"Score MAE moyen :\", scores.mean())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "222d2d6c-f4bb-40f7-a744-c72f59a4f149",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Conclusion\n",
    "La validation croisée offre une meilleure estimation de la qualité des modèles. De plus, elle simplifie votre code : vous n'avez plus besoin de gérer des ensembles de validation et d'entraînement séparés. Pour les petits jeux de données, c'est une amélioration précieuse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f1ce874-dffc-44fe-853e-917cb1a58d8e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
