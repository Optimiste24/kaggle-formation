{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c0b33202-d86c-4ee4-b33d-2e35c5dc007e",
   "metadata": {},
   "source": [
    "# Concours sur les prix de vente immobiliers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dd5d6ce-a633-4401-8edd-906854871b6d",
   "metadata": {},
   "source": [
    "Pour implémenter la validation croisée, tester différents paramètres et trouver la meilleure valeur de paramètre, nous allons suivre plusieurs étapes. Voici comment procéder pour améliorer votre code en intégrant ces éléments :\n",
    "\n",
    "1. **Création de la fonction utile** : Nous allons définir une fonction pour exécuter la validation croisée avec un modèle et des paramètres donnés.\n",
    "\n",
    "2. **Tester différentes valeurs de paramètres** : Utiliser un ensemble de paramètres pour entraîner et évaluer les performances du modèle sur différentes configurations.\n",
    "\n",
    "3. **Trouver la meilleure valeur de paramètre** : Sélectionner la valeur qui donne les meilleures performances, en utilisant la validation croisée pour éviter le surapprentissage.\n",
    "\n",
    "Voici comment vous pouvez intégrer cela à votre code :\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "98c17d96-53a1-4edc-b91e-99f8f6952969",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_10904\\133969498.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Importer les bibliothèques nécessaires\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompose\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mColumnTransformer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpipeline\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mPipeline\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'sklearn'"
     ]
    }
   ],
   "source": [
    "# Importer les bibliothèques nécessaires\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Charger les données\n",
    "train_path = 'train.csv'  # Remplacez par le chemin correct\n",
    "X_full = pd.read_csv(train_path, index_col='Id')\n",
    "\n",
    "test_path = 'test.csv'  # Remplacez par le chemin correct\n",
    "X_test_full = pd.read_csv(test_path, index_col='Id')\n",
    "\n",
    "# Prétraitement initial\n",
    "X_full.dropna(axis=0, subset=['SalePrice'], inplace=True)\n",
    "y = X_full['SalePrice']\n",
    "X_full.drop(['SalePrice'], axis=1, inplace=True)\n",
    "\n",
    "# Séparer les données d'entraînement et de validation\n",
    "X_train_full, X_valid_full, y_train, y_valid = train_test_split(\n",
    "    X_full, y, train_size=0.8, test_size=0.2, random_state=0\n",
    ")\n",
    "\n",
    "# Identifier les colonnes numériques et catégoriques\n",
    "categorical_cols = [\n",
    "    cname for cname in X_train_full.columns\n",
    "    if X_train_full[cname].dtype == \"object\" and X_train_full[cname].nunique() < 10\n",
    "]\n",
    "numerical_cols = [\n",
    "    cname for cname in X_train_full.columns\n",
    "    if X_train_full[cname].dtype in ['int64', 'float64']\n",
    "]\n",
    "\n",
    "# Garder les colonnes sélectionnées\n",
    "my_cols = categorical_cols + numerical_cols\n",
    "X_train = X_train_full[my_cols].copy()\n",
    "X_valid = X_valid_full[my_cols].copy()\n",
    "X_test = X_test_full[my_cols].copy()\n",
    "\n",
    "# Définir les transformations pour les colonnes numériques et catégoriques\n",
    "numerical_transformer = SimpleImputer(strategy='median')\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "# Combiner les transformations dans un ColumnTransformer\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_transformer, numerical_cols),\n",
    "        ('cat', categorical_transformer, categorical_cols)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Définir le modèle\n",
    "model = RandomForestRegressor(random_state=0)\n",
    "\n",
    "# Créer le pipeline\n",
    "my_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('model', model)\n",
    "])\n",
    "\n",
    "# Fonction pour effectuer la validation croisée avec GridSearchCV\n",
    "def cross_validate_model(pipeline, X_train, y_train, param_grid):\n",
    "    grid_search = GridSearchCV(pipeline, param_grid, cv=5, scoring='neg_mean_absolute_error')\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    return grid_search.best_estimator_, grid_search.best_params_, grid_search.best_score_\n",
    "\n",
    "# Définir la grille des hyperparamètres à tester\n",
    "param_grid = {\n",
    "    'model__n_estimators': [50, 100, 150],\n",
    "    'model__max_depth': [None, 10, 20],\n",
    "    'model__min_samples_split': [2, 5, 10]\n",
    "}\n",
    "\n",
    "# Appliquer la validation croisée pour trouver le meilleur modèle\n",
    "best_model, best_params, best_score = cross_validate_model(my_pipeline, X_train, y_train, param_grid)\n",
    "\n",
    "# Afficher les résultats\n",
    "print(\"Meilleur modèle :\", best_model)\n",
    "print(\"Meilleurs paramètres :\", best_params)\n",
    "print(\"Meilleur score MAE :\", -best_score)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "101d39fb-db85-48a5-816d-e3f9354fea3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE sur les données de validation : 17438.391436895043\n",
      "Fichier de soumission créé : submission_best_model.csv\n"
     ]
    }
   ],
   "source": [
    "# Entraîner le meilleur modèle sur l'ensemble d'entraînement complet\n",
    "best_model.fit(X_train, y_train)\n",
    "\n",
    "# Faire des prédictions sur les données de validation\n",
    "preds_valid = best_model.predict(X_valid)\n",
    "mae = mean_absolute_error(y_valid, preds_valid)\n",
    "print(f'MAE sur les données de validation : {mae}')\n",
    "\n",
    "# Faire des prédictions sur les données de test\n",
    "preds_test = best_model.predict(X_test)\n",
    "\n",
    "# Préparer le fichier de soumission\n",
    "output = pd.DataFrame({'Id': X_test.index, 'SalePrice': preds_test})\n",
    "output.to_csv('submission_best_model.csv', index=False)\n",
    "print(\"Fichier de soumission créé : submission_best_model.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "862cf879-39af-4a74-a967-3d848b5cf456",
   "metadata": {},
   "source": [
    "### Explication des modifications :\n",
    "\n",
    "1. **Fonction `cross_validate_model`** : Cette fonction utilise `GridSearchCV` pour effectuer la recherche par grille sur les hyperparamètres spécifiés dans `param_grid`. Elle effectue une validation croisée avec 5 plis (`cv=5`) et renvoie le meilleur modèle, les meilleurs paramètres et le meilleur score.\n",
    "\n",
    "2. **Recherche par grille** : La grille des hyperparamètres inclut différentes valeurs pour `n_estimators`, `max_depth`, et `min_samples_split` dans le modèle `RandomForestRegressor`. Ces paramètres sont ajustés pour trouver la combinaison qui minimise l'erreur absolue moyenne (MAE).\n",
    "\n",
    "3. **Entraînement et prédiction** : Le modèle avec les meilleurs paramètres est ensuite entraîné sur l'ensemble d'entraînement complet, et les prédictions sont effectuées sur les données de validation et de test. Un fichier de soumission est généré avec les prédictions sur les données de test.\n",
    "\n",
    "Cette approche vous permet de tester différentes configurations du modèle et de choisir la meilleure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bb3c555-cef0-46c9-9a21-b2fda6075543",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
