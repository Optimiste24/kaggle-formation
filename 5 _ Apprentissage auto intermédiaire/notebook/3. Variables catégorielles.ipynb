{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4f71e019-f6e1-490c-ac5b-ae70f372daba",
   "metadata": {},
   "source": [
    "# Variables catégorielles\n",
    "Il existe de nombreuses données non numériques. Voici comment les utiliser pour l’apprentissage automatique."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fd9f4a7-f2cf-48f2-ad49-b022567a2767",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "Une variable catégorielle ne prend qu’un nombre limité de valeurs.\n",
    "\n",
    "Prenons l’exemple d’un sondage qui demande à quelle fréquence vous prenez un petit-déjeuner et qui propose quatre options : \"Jamais\", \"Rarement\", \"La plupart des jours\" ou \"Tous les jours\". Dans ce cas, les données sont catégorielles, car les réponses appartiennent à un ensemble fixe de catégories.\n",
    "\n",
    "Si les gens répondaient à un sondage sur la marque de voiture qu’ils possèdent, les réponses tomberaient dans des catégories comme \"Honda\", \"Toyota\" et \"Ford\". Dans ce cas, les données sont également catégorielles.\n",
    "\n",
    "Vous obtiendrez une erreur si vous essayez d’insérer ces variables dans la plupart des modèles d’apprentissage automatique en Python sans les prétraiter au préalable. \n",
    "\n",
    "Dans ce tutoriel, nous allons comparer trois approches que vous pouvez utiliser pour préparer vos données catégorielles."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb514a23-a012-4bad-b66f-559bf59374a8",
   "metadata": {},
   "source": [
    "## Trois approches\n",
    "#### 1) Supprimer les variables catégorielles\n",
    "L’approche la plus simple pour traiter les variables catégorielles est de simplement les supprimer du jeu de données. Cette approche ne fonctionnera bien que si les colonnes ne contiennent pas d’informations utiles.\n",
    "\n",
    "#### 2) Encodage ordinal\n",
    "L’encodage ordinal attribue à chaque valeur unique un entier différent.\n",
    "\n",
    "Exemple :\n",
    "\n",
    "    Jamais\tRarement\tLa plupart des jours\tTous les jours\n",
    "    0\t       1\t               2\t              3\n",
    "\n",
    "Cette approche suppose un ordre des catégories : \"Jamais\" (0) < \"Rarement\" (1) < \"La plupart des jours\" (2) < \"Tous les jours\" (3).\n",
    "\n",
    "Cette hypothèse est logique dans cet exemple, car il existe un classement indiscutable des catégories. Toutes les variables catégorielles n’ont pas un ordre clair dans leurs valeurs, mais nous appelons celles qui en ont des ***variables ordinales***. \n",
    "\n",
    "**Pour les modèles basés sur les arbres (comme les arbres de décision et les forêts aléatoires), vous pouvez vous attendre à ce que l’encodage ordinal fonctionne bien avec les variables ordinales.**\n",
    "\n",
    "#### 3) Encodage one-hot\n",
    "L’encodage one-hot crée de nouvelles colonnes indiquant la présence (ou l’absence) de chaque valeur possible dans les données d’origine.\n",
    "\n",
    "*Exemple* :\n",
    "\n",
    "Dans le jeu de données d’origine, \"Couleur\" est une variable catégorielle avec trois catégories : \"Rouge\", \"Jaune\" et \"Vert\". L’encodage one-hot correspondant contient une colonne pour chaque valeur possible et une ligne pour chaque ligne du jeu de données d’origine. Chaque fois que la valeur d’origine était \"Rouge\", nous mettons un 1 dans la colonne \"Rouge\" ; si la valeur d’origine était \"Jaune\", nous mettons un 1 dans la colonne \"Jaune\", et ainsi de suite.\n",
    "\n",
    "En contraste avec l’encodage ordinal, l’encodage one-hot ne suppose pas d’ordre dans les catégories. Ainsi, vous pouvez vous attendre à ce que cette approche fonctionne particulièrement bien s’il n’y a pas d’ordre clair dans les données catégorielles (par exemple, \"Rouge\" n’est ni plus ni moins que \"Jaune\"). \n",
    "\n",
    "**Nous appelons les variables catégorielles sans classement intrinsèque des variables nominales.**\n",
    "\n",
    "L’encodage one-hot ne fonctionne généralement pas bien si la variable catégorielle prend un grand nombre de valeurs (c’est-à-dire que vous ne l’utiliserez généralement pas pour des variables prenant plus de 15 valeurs différentes).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73a7e655-4504-45b6-a7ca-8dad3b303242",
   "metadata": {},
   "source": [
    "## Exemple\n",
    "Comme dans le tutoriel précédent, nous allons travailler avec le jeu de données sur **les logements de Melbourne**.\n",
    "\n",
    "Nous ne nous concentrerons pas sur l’étape de chargement des données. Au lieu de cela, vous pouvez imaginer que vous êtes à un point où vous avez déjà les données d’entraînement et de validation dans X_train, X_valid, y_train, et y_valid.\n",
    "\n",
    "Nous examinons rapidement les données d’entraînement avec la méthode head() ci-dessous."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "0a0b61f8-c389-4b95-8f44-3e29913d4694",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Colonnes restantes :\n",
      "Index(['Rooms', 'Type', 'Price', 'Method', 'Distance', 'Postcode', 'Bedroom2',\n",
      "       'Bathroom', 'Car', 'Landsize', 'BuildingArea', 'YearBuilt', 'Lattitude',\n",
      "       'Longtitude', 'Regionname', 'Propertycount'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Charger les données\n",
    "melbourne_file_path = 'melb_data.csv'\n",
    "melbourne_data = pd.read_csv(melbourne_file_path)\n",
    "\n",
    "# Identifier les variables catégorielles\n",
    "categorical_cols = melbourne_data.select_dtypes(include=['object']).columns\n",
    "\n",
    "# Variables catégorielles à conserver\n",
    "keep_cols = ['Type', 'Method', 'Regionname']\n",
    "\n",
    "# Supprimer les autres variables catégorielles\n",
    "melbourne_data = melbourne_data.drop(columns=[col for col in categorical_cols if col not in keep_cols])\n",
    "\n",
    "# Vérifier les colonnes restantes\n",
    "print(\"Colonnes restantes :\")\n",
    "print(melbourne_data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "bb470f63-19fd-4aa4-9833-5c53f1098d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Supprimer les lignes avec une cible manquante, séparer la cible des prédicteurs\n",
    "melbourne_data.dropna(axis=0, subset=['Price'], inplace=True)\n",
    "y = melbourne_data.Price\n",
    "X = melbourne_data.drop(['Price'], axis=1)  # Retirez inplace=True\n",
    "\n",
    "# Diviser en données d'entraînement et de validation\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, train_size=0.8, test_size=0.2, random_state=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "01b750ba-b446-4e18-8d94-f5176997b4f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rooms</th>\n",
       "      <th>Type</th>\n",
       "      <th>Method</th>\n",
       "      <th>Distance</th>\n",
       "      <th>Postcode</th>\n",
       "      <th>Bedroom2</th>\n",
       "      <th>Bathroom</th>\n",
       "      <th>Car</th>\n",
       "      <th>Landsize</th>\n",
       "      <th>BuildingArea</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>Lattitude</th>\n",
       "      <th>Longtitude</th>\n",
       "      <th>Regionname</th>\n",
       "      <th>Propertycount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12167</th>\n",
       "      <td>1</td>\n",
       "      <td>u</td>\n",
       "      <td>S</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3182.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1940.0</td>\n",
       "      <td>-37.85984</td>\n",
       "      <td>144.9867</td>\n",
       "      <td>Southern Metropolitan</td>\n",
       "      <td>13240.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6524</th>\n",
       "      <td>2</td>\n",
       "      <td>h</td>\n",
       "      <td>SA</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3016.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>193.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-37.85800</td>\n",
       "      <td>144.9005</td>\n",
       "      <td>Western Metropolitan</td>\n",
       "      <td>6380.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8413</th>\n",
       "      <td>3</td>\n",
       "      <td>h</td>\n",
       "      <td>S</td>\n",
       "      <td>12.6</td>\n",
       "      <td>3020.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>555.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-37.79880</td>\n",
       "      <td>144.8220</td>\n",
       "      <td>Western Metropolitan</td>\n",
       "      <td>3755.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2919</th>\n",
       "      <td>3</td>\n",
       "      <td>u</td>\n",
       "      <td>SP</td>\n",
       "      <td>13.0</td>\n",
       "      <td>3046.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>265.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1995.0</td>\n",
       "      <td>-37.70830</td>\n",
       "      <td>144.9158</td>\n",
       "      <td>Northern Metropolitan</td>\n",
       "      <td>8870.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6043</th>\n",
       "      <td>3</td>\n",
       "      <td>h</td>\n",
       "      <td>S</td>\n",
       "      <td>13.3</td>\n",
       "      <td>3020.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>673.0</td>\n",
       "      <td>673.0</td>\n",
       "      <td>1970.0</td>\n",
       "      <td>-37.76230</td>\n",
       "      <td>144.8272</td>\n",
       "      <td>Western Metropolitan</td>\n",
       "      <td>4217.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Rooms Type Method  Distance  Postcode  Bedroom2  Bathroom  Car  \\\n",
       "12167      1    u      S       5.0    3182.0       1.0       1.0  1.0   \n",
       "6524       2    h     SA       8.0    3016.0       2.0       2.0  1.0   \n",
       "8413       3    h      S      12.6    3020.0       3.0       1.0  1.0   \n",
       "2919       3    u     SP      13.0    3046.0       3.0       1.0  1.0   \n",
       "6043       3    h      S      13.3    3020.0       3.0       1.0  2.0   \n",
       "\n",
       "       Landsize  BuildingArea  YearBuilt  Lattitude  Longtitude  \\\n",
       "12167       0.0           NaN     1940.0  -37.85984    144.9867   \n",
       "6524      193.0           NaN        NaN  -37.85800    144.9005   \n",
       "8413      555.0           NaN        NaN  -37.79880    144.8220   \n",
       "2919      265.0           NaN     1995.0  -37.70830    144.9158   \n",
       "6043      673.0         673.0     1970.0  -37.76230    144.8272   \n",
       "\n",
       "                  Regionname  Propertycount  \n",
       "12167  Southern Metropolitan        13240.0  \n",
       "6524    Western Metropolitan         6380.0  \n",
       "8413    Western Metropolitan         3755.0  \n",
       "2919   Northern Metropolitan         8870.0  \n",
       "6043    Western Metropolitan         4217.0  "
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf31fe45-e573-4593-b79a-d2e6035f09ce",
   "metadata": {},
   "source": [
    "Nous obtenons ensuite une liste de toutes les variables catégorielles dans les données d’entraînement en vérifiant le type de données (dtype) de chaque colonne. Le type object indique qu’une colonne contient du texte (il pourrait théoriquement y avoir d’autres choses, mais ce n’est pas important pour nos besoins). \n",
    "\n",
    "Pour ce jeu de données, **les colonnes contenant du texte indiquent des variables catégorielles.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "fe144049-14a2-4df9-8cb6-9edbc1510d2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variables catégorielles :\n",
      "['Type', 'Method', 'Regionname']\n"
     ]
    }
   ],
   "source": [
    "# Obtenir la liste des variables catégorielles  \n",
    "s = (X_train.dtypes == 'object')\n",
    "object_cols = list(s[s].index)\n",
    "\n",
    "print(\"Variables catégorielles :\")\n",
    "print(object_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8768dd1e-c188-4805-a862-f960dda2e1bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6a9f8e0c-1534-46f8-8076-a25e1c098784",
   "metadata": {},
   "source": [
    "## Approche n°1 : Supprimer les variables catégorielles\n",
    "En tant que première approche, utilisons uniquement les colonnes numériques du jeu de données. Cela implique d’éliminer les variables catégorielles, ainsi que toutes les colonnes non numériques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "0d527a50-0936-4c4d-9be4-88022a2c48d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Supprimer les colonnes catégorielles  \n",
    "drop_X_train = X_train.select_dtypes(exclude=['object'])\n",
    "drop_X_valid = X_valid.select_dtypes(exclude=['object'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e94ca7b-153b-4271-90dd-a72c50f7fc62",
   "metadata": {},
   "source": [
    "Ensuite, nous **évaluons le modèle**. La fonction ci-dessous est un raccourci pour évaluer la performance d’un modèle. Si vous n’êtes pas sûr de son fonctionnement, passez simplement au code qui suit ; il n’est pas essentiel de comprendre chaque détail pour suivre le tutoriel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "89a719a5-945c-4a81-a2f0-fd3993df0e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "def score_dataset(X_train, X_valid, y_train, y_valid):\n",
    "    model = RandomForestRegressor(n_estimators=100, random_state=0)\n",
    "    model.fit(X_train, y_train)\n",
    "    preds = model.predict(X_valid)\n",
    "    return mean_absolute_error(y_valid, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "65ca3caa-ac5e-40f2-8b07-755eb74a5985",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE lorsque les colonnes catégorielles sont supprimées :\n",
      "169107.7515611193\n"
     ]
    }
   ],
   "source": [
    "# Évaluer le modèle  \n",
    "print(\"MAE lorsque les colonnes catégorielles sont supprimées :\")\n",
    "print(score_dataset(drop_X_train, drop_X_valid, y_train, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f5cf393-13b9-44ad-8a3a-824b02f66c78",
   "metadata": {},
   "source": [
    "## Approche n°2 : Encodage ordinal\n",
    "Nous appliquons l’encodage ordinal, en utilisant la classe ***OrdinalEncoder*** de scikit-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "c4f5834b-fd12-4c41-9854-4238c09dbe56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE avec l’encodage ordinal :\n",
      "162121.2173048601\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "# Appliquer l’encodage ordinal aux colonnes catégorielles  \n",
    "ordinal_encoder = OrdinalEncoder()\n",
    "label_X_train = X_train.copy()\n",
    "label_X_valid = X_valid.copy()\n",
    "\n",
    "label_X_train[object_cols] = ordinal_encoder.fit_transform(X_train[object_cols])\n",
    "label_X_valid[object_cols] = ordinal_encoder.transform(X_valid[object_cols])\n",
    "\n",
    "# Évaluer le modèle  \n",
    "print(\"MAE avec l’encodage ordinal :\")\n",
    "print(score_dataset(label_X_train, label_X_valid, y_train, y_valid))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3a65e71-a57d-4f9e-844c-3a5a4aafc76b",
   "metadata": {},
   "source": [
    "Avec l’encodage ordinal, l’erreur absolue moyenne (MAE) est plus basse que lorsque les colonnes catégorielles sont supprimées, ce qui indique que cette approche utilise mieux les données."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "250ab094-fece-4c28-88c4-83efd87889db",
   "metadata": {},
   "source": [
    "## Approche n°3 : Encodage one-hot\n",
    "Enfin, essayons l’encodage one-hot, en utilisant la classe ***OneHotEncoder*** de scikit-learn avec l’option ***handle_unknown='ignore'*** pour éviter les erreurs lorsque les données de validation contiennent des catégories qui ne figurent pas dans les données d’entraînement.\n",
    "\n",
    "En raison de la grande taille des jeux de données après encodage one-hot, nous utilisons ***sparse=False*** pour convertir les résultats en un tableau NumPy denses (cela facilite l’utilisation avec scikit-learn)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "984c4499-4ca0-4c45-91f2-1dec5842e7db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE avec l’encodage one-hot :\n",
      "160683.8470632583\n"
     ]
    }
   ],
   "source": [
    "# Encodage One-Hot\n",
    "onehot_encoder = OneHotEncoder(handle_unknown='ignore', sparse_output=False)\n",
    "\n",
    "OH_cols_train = pd.DataFrame(onehot_encoder.fit_transform(X_train[object_cols]))\n",
    "OH_cols_valid = pd.DataFrame(onehot_encoder.transform(X_valid[object_cols]))\n",
    "\n",
    "# Aligner les indices\n",
    "OH_cols_train.index = X_train.index\n",
    "OH_cols_valid.index = X_valid.index\n",
    "\n",
    "# Supprimer les colonnes catégorielles originales\n",
    "X_train = X_train.drop(object_cols, axis=1)\n",
    "X_valid = X_valid.drop(object_cols, axis=1)\n",
    "\n",
    "# Ajouter les colonnes encodées\n",
    "X_train = pd.concat([X_train, OH_cols_train], axis=1)\n",
    "X_valid = pd.concat([X_valid, OH_cols_valid], axis=1)\n",
    "\n",
    "# Convertir les noms de colonnes en chaînes de caractères\n",
    "X_train.columns = X_train.columns.astype(str)\n",
    "X_valid.columns = X_valid.columns.astype(str)\n",
    "\n",
    "# Fonction pour évaluer le modèle\n",
    "def score_dataset(X_train, X_valid, y_train, y_valid):\n",
    "    model = RandomForestRegressor(n_estimators=100, random_state=0)\n",
    "    model.fit(X_train, y_train)\n",
    "    preds = model.predict(X_valid)\n",
    "    return mean_absolute_error(y_valid, preds)\n",
    "\n",
    "# Évaluer le modèle\n",
    "print(\"MAE avec l’encodage one-hot :\")\n",
    "print(score_dataset(X_train, X_valid, y_train, y_valid))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22e8bb79-93d5-4621-a442-8d2da82540cf",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "Dans ce cas, l’encodage ordinal et l’encodage one-hot ont produit des résultats similaires. Mais quelle approche est la meilleure ? Cela dépend du problème :\n",
    "\n",
    "L’encodage ordinal fonctionne bien si les variables catégorielles ont un ordre clair.\n",
    "L’encodage one-hot est plus approprié si aucune relation d’ordre n’existe entre les catégories.\n",
    "\n",
    "Dans cet exemple, les catégories de la **colonne Regionname sont nominales** (sans ordre clair). Ainsi, l’encodage one-hot pourrait être un meilleur choix, bien que la performance ne soit pas significativement meilleure ici.\n",
    "\n",
    "En général, l’encodage one-hot est plus sûr, car il fait moins d’hypothèses sur les données, mais il peut aussi augmenter considérablement la taille du jeu de données."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1b9241a-c30f-44b7-93d2-b715b7baa352",
   "metadata": {},
   "source": [
    "# Problèmes eventuels\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Le message montre que les colonnes `Condition2` dans les données d'entraînement (`X_train`) et de validation (`X_valid`) ont des valeurs uniques différentes. Cela peut poser un problème pour les modèles d'apprentissage automatique, surtout si certaines valeurs apparaissent dans l'ensemble de validation mais pas dans l'ensemble d'entraînement (ou vice versa).\n",
    "\n",
    "### **Problème principal :**\n",
    "- Les valeurs uniques dans `Condition2` incluent des catégories différentes entre les deux ensembles de données. Par exemple :\n",
    "  - Dans `X_train`, la catégorie `'PosA'` est présente mais absente dans `X_valid`.\n",
    "  - Dans `X_valid`, les catégories `'RRAn'` et `'RRNn'` sont présentes mais absentes dans `X_train`.\n",
    "\n",
    "Cela rend difficile l'utilisation d'un encodage catégoriel direct sans traitement spécial.\n",
    "\n",
    "---\n",
    "\n",
    "### **Prochaines étapes suggérées :**\n",
    "\n",
    "#### 1. **Ignorer les colonnes problématiques :**\n",
    "Si la colonne `Condition2` n'est pas critique pour votre modèle, vous pouvez simplement la supprimer des deux ensembles.\n",
    "\n",
    "```python\n",
    "X_train = X_train.drop(['Condition2'], axis=1)\n",
    "X_valid = X_valid.drop(['Condition2'], axis=1)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "#### 2. **Utiliser l'encodage catégoriel avec `handle_unknown='ignore'` :**\n",
    "Si vous souhaitez conserver la colonne `Condition2`, vous pouvez appliquer un encodage catégoriel tel que l'encodage ordinal ou l'encodage one-hot avec une gestion explicite des catégories inconnues dans l'ensemble de validation.\n",
    "\n",
    "**Exemple avec `OneHotEncoder` :**\n",
    "```python\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Instancier l'encodage one-hot avec gestion des valeurs inconnues\n",
    "onehot_encoder = OneHotEncoder(handle_unknown='ignore', sparse_output=False)\n",
    "\n",
    "# Appliquer l'encodage à la colonne 'Condition2'\n",
    "OH_cols_train = pd.DataFrame(onehot_encoder.fit_transform(X_train[['Condition2']]))\n",
    "OH_cols_valid = pd.DataFrame(onehot_encoder.transform(X_valid[['Condition2']]))\n",
    "\n",
    "# Ajouter les colonnes encodées à X_train et X_valid après avoir supprimé 'Condition2'\n",
    "X_train = X_train.drop(['Condition2'], axis=1).reset_index(drop=True)\n",
    "X_valid = X_valid.drop(['Condition2'], axis=1).reset_index(drop=True)\n",
    "\n",
    "X_train = pd.concat([X_train, OH_cols_train], axis=1)\n",
    "X_valid = pd.concat([X_valid, OH_cols_valid], axis=1)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "#### 3. **Remplacer les valeurs inconnues par une catégorie \"Autre\" :**\n",
    "Vous pouvez également créer une nouvelle catégorie \"Other\" pour gérer les valeurs absentes de manière explicite.\n",
    "\n",
    "```python\n",
    "X_train['Condition2'] = X_train['Condition2'].replace({'RRAn': 'Other', 'RRNn': 'Other'})\n",
    "X_valid['Condition2'] = X_valid['Condition2'].replace({'PosA': 'Other'})\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "Ces approches dépendent de l'importance de la colonne `Condition2` dans votre modèle. Si elle est très utile, l'encodage est préférable ; sinon, vous pouvez la supprimer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "989c3735-9d07-4195-96a0-33eb001ab49c",
   "metadata": {},
   "source": [
    "Bien sûr ! Voici la traduction en français :\n",
    "\n",
    "---\n",
    "\n",
    "### **Explication :**\n",
    "Lorsque vous utilisez un encodeur ordinal, toutes les catégories présentes dans les données de validation doivent également être présentes dans les données d'entraînement. Sinon, l'encodeur génère une erreur, car il ne peut pas attribuer de valeur entière à des catégories inconnues.\n",
    "\n",
    "Voici un résumé des résultats et des étapes suivantes :\n",
    "\n",
    "---\n",
    "\n",
    "### **Catégories identifiées :**\n",
    "- **Colonnes pouvant être encodées ordinalement :**  \n",
    "  Ces colonnes ne contiennent que des valeurs qui existent à la fois dans les données d'entraînement et dans les données de validation. Vous pouvez les encoder en toute sécurité avec un `OrdinalEncoder`.\n",
    "\n",
    "  **Exemples :** `'MSZoning', 'Street', 'LotShape', 'Neighborhood', etc.`\n",
    "\n",
    "- **Colonnes problématiques :**  \n",
    "  Ces colonnes contiennent des catégories dans les données de validation qui n'existent pas dans les données d'entraînement. Elles doivent être soit supprimées, soit traitées différemment.\n",
    "\n",
    "  **Exemples :** `'RoofMatl', 'Condition2', 'Functional'`\n",
    "\n",
    "---\n",
    "\n",
    "### **Approche suggérée :**\n",
    "#### 1. **Encodage ordinal des colonnes sûres (`good_label_cols`)**  \n",
    "Vous pouvez appliquer un `OrdinalEncoder` uniquement sur les colonnes listées dans `good_label_cols`.\n",
    "\n",
    "#### 2. **Suppression des colonnes problématiques (`bad_label_cols`)**  \n",
    "Les colonnes identifiées dans `bad_label_cols` doivent être retirées avant l'entraînement du modèle.\n",
    "\n",
    "---\n",
    "\n",
    "```python\n",
    "# Categorical columns in the training data\n",
    "object_cols = [col for col in X_train.columns if X_train[col].dtype == \"object\"]\n",
    "\n",
    "# Columns that can be safely ordinal encoded\n",
    "good_label_cols = [col for col in object_cols if \n",
    "                   set(X_valid[col]).issubset(set(X_train[col]))]\n",
    "        \n",
    "# Problematic columns that will be dropped from the dataset\n",
    "bad_label_cols = list(set(object_cols)-set(good_label_cols))\n",
    "        \n",
    "print('Categorical columns that will be ordinal encoded:', good_label_cols)\n",
    "print('\\nCategorical columns that will be dropped from the dataset:', bad_label_cols)\n",
    "```\n",
    "---\n",
    "\n",
    "\n",
    "### **Code pour implémenter ces étapes :**\n",
    "\n",
    "```python\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "# Supprimer les colonnes problématiques\n",
    "X_train.drop(bad_label_cols, axis=1, inplace=True)\n",
    "X_valid.drop(bad_label_cols, axis=1, inplace=True)\n",
    "\n",
    "# Appliquer l'encodage ordinal sur les colonnes sûres\n",
    "ordinal_encoder = OrdinalEncoder()\n",
    "\n",
    "# Encoder les colonnes catégorielles\n",
    "X_train[good_label_cols] = ordinal_encoder.fit_transform(X_train[good_label_cols])\n",
    "X_valid[good_label_cols] = ordinal_encoder.transform(X_valid[good_label_cols])\n",
    "\n",
    "# Vérification des résultats\n",
    "print(X_train.head())\n",
    "print(X_valid.head())\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **Pourquoi cette approche fonctionne :**\n",
    "1. En supprimant les colonnes problématiques, vous éliminez les erreurs liées aux catégories inconnues dans les données de validation.\n",
    "2. En encodant uniquement les colonnes sûres, vous assurez que toutes les catégories sont correctement traitées dans les deux ensembles.\n",
    "\n",
    "---\n",
    "\n",
    "Cela garantit que vos données sont prêtes pour l'entraînement d'un modèle sans erreurs liées aux variables catégorielles."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64df023f-1893-43e9-bac2-4016cc7a2d89",
   "metadata": {},
   "source": [
    "### Explication et Correction : \n",
    "\n",
    "L’objectif ici est de préparer les données pour l’entraînement en appliquant un encodage ordinal sur les colonnes catégorielles sûres (`good_label_cols`) et en supprimant les colonnes problématiques (`bad_label_cols`). Cela permet de convertir les données catégorielles en valeurs numériques tout en évitant les erreurs liées aux catégories inconnues.\n",
    "\n",
    "---\n",
    "\n",
    "### **Étapes à suivre** :\n",
    "\n",
    "1. **Supprimer les colonnes problématiques (`bad_label_cols`)** :  \n",
    "   Ces colonnes contiennent des catégories dans les données de validation qui n’existent pas dans les données d’entraînement, donc elles sont supprimées des deux ensembles (`X_train` et `X_valid`).\n",
    "\n",
    "2. **Encoder ordinalement les colonnes catégorielles sûres (`good_label_cols`)** :  \n",
    "   Cela convertit les valeurs catégorielles en valeurs numériques de manière ordonnée.\n",
    "\n",
    "3. **Créer de nouveaux DataFrames (`label_X_train` et `label_X_valid`)** :  \n",
    "   Ces DataFrames contiendront les colonnes restantes après suppression et encodage.\n",
    "\n",
    "---\n",
    "\n",
    "### **Code corrigé** :\n",
    "\n",
    "```python\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "# Supprimer les colonnes catégorielles problématiques\n",
    "label_X_train = X_train.drop(bad_label_cols, axis=1)\n",
    "label_X_valid = X_valid.drop(bad_label_cols, axis=1)\n",
    "\n",
    "# Appliquer l'encodage ordinal aux colonnes catégorielles sûres\n",
    "ordinal_encoder = OrdinalEncoder()\n",
    "label_X_train[good_label_cols] = ordinal_encoder.fit_transform(label_X_train[good_label_cols])\n",
    "label_X_valid[good_label_cols] = ordinal_encoder.transform(label_X_valid[good_label_cols])\n",
    "\n",
    "# Vérification des résultats\n",
    "print(label_X_train.head())\n",
    "print(label_X_valid.head())\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **Pourquoi ce code fonctionne** :\n",
    "1. **Suppression des colonnes problématiques** :  \n",
    "   - Les colonnes listées dans `bad_label_cols` sont éliminées, évitant ainsi les erreurs dues à des catégories inconnues.\n",
    "\n",
    "2. **Encodage ordinal** :  \n",
    "   - La méthode `fit_transform` est appliquée aux données d'entraînement pour ajuster l'encodeur aux catégories présentes.\n",
    "   - La méthode `transform` est appliquée aux données de validation pour s’assurer que les mêmes règles d’encodage sont suivies.\n",
    "\n",
    "3. **Intégrité des données** :  \n",
    "   - Les colonnes catégorielles sûres (`good_label_cols`) sont encodées de manière cohérente pour les deux ensembles, tout en maintenant la structure globale des données.\n",
    "\n",
    "---\n",
    "\n",
    "### **Résultat attendu** :\n",
    "- Le modèle peut maintenant utiliser les DataFrames `label_X_train` et `label_X_valid`, qui sont entièrement numériques et exempts d’erreurs liées aux catégories inconnues. \n",
    "\n",
    "Vous pouvez passer à l’étape suivante en toute confiance ! 😊"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dad6b819-5afd-451b-8a2f-72b7fbff8adb",
   "metadata": {},
   "source": [
    "### Explication :\n",
    "\n",
    "Le but de ce code est de préparer une analyse des colonnes catégorielles en étudiant le nombre d'entrées uniques dans chacune d'elles. Cela aide à identifier les colonnes qui pourraient poser des problèmes lors de l'encodage, par exemple :\n",
    "\n",
    "1. **Colonnes avec un petit nombre de catégories uniques** :  \n",
    "   Ces colonnes sont généralement bien adaptées à des techniques comme l'encodage ordinal ou one-hot.\n",
    "\n",
    "2. **Colonnes avec un grand nombre de catégories uniques** :  \n",
    "   Ces colonnes peuvent poser problème avec un encodage one-hot, car cela pourrait générer un très grand nombre de nouvelles colonnes.\n",
    "\n",
    "---\n",
    "\n",
    "### **Étapes du code** :\n",
    "\n",
    "1. **Nombre d'entrées uniques par colonne** :\n",
    "   ```python\n",
    "   object_nunique = list(map(lambda col: X_train[col].nunique(), object_cols))\n",
    "   ```\n",
    "   - La fonction `nunique()` calcule le nombre d'entrées uniques dans chaque colonne catégorielle.\n",
    "   - `map()` applique cette fonction à toutes les colonnes catégorielles de `object_cols`.\n",
    "\n",
    "2. **Associer les colonnes à leur nombre d'entrées uniques** :\n",
    "   ```python\n",
    "   d = dict(zip(object_cols, object_nunique))\n",
    "   ```\n",
    "   - Le dictionnaire `d` relie chaque colonne catégorielle (`object_cols`) à son nombre correspondant d'entrées uniques (`object_nunique`).\n",
    "\n",
    "3. **Trier les colonnes par nombre d'entrées uniques** :\n",
    "   ```python\n",
    "   sorted(d.items(), key=lambda x: x[1])\n",
    "   ```\n",
    "   - Les colonnes sont triées par leur nombre d'entrées uniques dans l'ordre croissant. Cela permet d'identifier facilement les colonnes avec peu ou beaucoup de catégories.\n",
    "\n",
    "---\n",
    "\n",
    "### **Résultat attendu** :\n",
    "\n",
    "La sortie du code sera une liste triée de tuples, où :\n",
    "- Chaque tuple contient une colonne catégorielle et son nombre d'entrées uniques.\n",
    "- Les colonnes sont listées par ordre croissant du nombre d'entrées uniques.\n",
    "\n",
    "Par exemple :\n",
    "```python\n",
    "[('Street', 2), ('CentralAir', 2), ..., ('Neighborhood', 25), ('Exterior1st', 28)]\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **Utilité de cette analyse** :\n",
    "- Vous pouvez déterminer quelles colonnes sont idéales pour un encodage ordinal ou one-hot.\n",
    "- Vous identifierez les colonnes à ignorer ou à traiter différemment si elles ont un très grand nombre de catégories uniques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc0c5c47-591f-4b23-ad13-9f6e8967f850",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-mooc-rr-jupyter]",
   "language": "python",
   "name": "conda-env-.conda-mooc-rr-jupyter-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
