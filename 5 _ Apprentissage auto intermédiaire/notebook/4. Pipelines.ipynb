{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0dea2769-def1-44d5-8708-a2080eb1aae5",
   "metadata": {},
   "source": [
    "# Pipelines\n",
    "Une compétence essentielle pour déployer (et même tester) des modèles complexes avec prétraitement."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "febaf995-a8a3-417a-8be2-8d30f148635f",
   "metadata": {},
   "source": [
    "Dans ce tutoriel, vous apprendrez à utiliser les pipelines pour simplifier votre code de modélisation.\n",
    "\n",
    "## Introduction\n",
    "Les pipelines sont un moyen simple d'organiser votre code de prétraitement des données et de modélisation. Concrètement, un pipeline regroupe les étapes de prétraitement et de modélisation, de sorte que vous puissiez utiliser l'ensemble comme une seule étape.\n",
    "\n",
    "De nombreux **data scientists** créent des modèles sans pipelines, mais les pipelines offrent d'importants avantages :\n",
    "\n",
    "- **Code plus propre** : Gérer les données à chaque étape de prétraitement peut devenir compliqué. Avec un pipeline, vous n'aurez pas besoin de suivre manuellement vos données d'entraînement et de validation à chaque étape.\n",
    "- **Moins de bugs** : Il y a moins de risques d'appliquer une étape de manière incorrecte ou d'oublier une étape de prétraitement.\n",
    "- **Facilité de mise en production** : Passer d'un prototype à un modèle déployable à grande échelle peut être étonnamment difficile. Bien que nous n'abordions pas tous les aspects connexes ici, les pipelines peuvent faciliter cette transition.\n",
    "- **Plus d'options pour la validation des modèles** : Vous verrez un exemple dans le prochain tutoriel, qui couvre la validation croisée."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b4bd72e-02f8-41fc-968a-c97323931304",
   "metadata": {},
   "source": [
    "### Exemple\n",
    "Comme dans le tutoriel précédent, nous travaillerons avec le jeu de données sur le logement à Melbourne.\n",
    "\n",
    "Nous ne nous concentrerons pas sur l'étape de chargement des données. Imaginez que vous avez déjà les données d'entraînement et de validation dans `X_train` , `X_valid` , `y_train` et `y_valid`.\n",
    "\n",
    "Nous jetons un coup d'œil aux données d'entraînement avec la méthode head(). \n",
    "\n",
    "Remarquez que les données contiennent à la fois des données catégoriques et des colonnes avec des valeurs manquantes. Avec un pipeline, il est facile de traiter les deux !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6160673d-fc87-449c-acaf-b1a8ffa94b07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taille de X_train : (10864, 15)\n",
      "Taille de X_valid : (2716, 15)\n",
      "Taille de y_train : (10864,)\n",
      "Taille de y_valid : (2716,)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Charger les données\n",
    "melbourne_file_path = 'melb_data.csv'\n",
    "melbourne_data = pd.read_csv(melbourne_file_path)\n",
    "\n",
    "# Supprimer les lignes avec une cible manquante, séparer la cible des prédicteurs\n",
    "melbourne_data.dropna(axis=0, subset=['Price'], inplace=True)\n",
    "y = melbourne_data['Price']\n",
    "X = melbourne_data.drop(['Price'], axis=1)  # Retirez inplace=True\n",
    "\n",
    "# Identifier les colonnes numériques et catégoriques\n",
    "numerical_cols = X.select_dtypes(include=['int64', 'float64']).columns\n",
    "categorical_cols = X.select_dtypes(include=['object']).columns\n",
    "\n",
    "# Variables catégorielles à conserver\n",
    "keep_cols = ['Type', 'Method', 'Regionname']\n",
    "\n",
    "# Supprimer les autres variables catégorielles\n",
    "X = X.drop(columns=[col for col in categorical_cols if col not in keep_cols])\n",
    "\n",
    "# Diviser en données d'entraînement et de validation\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, train_size=0.8, test_size=0.2, random_state=0)\n",
    "\n",
    "# Vérifier les dimensions\n",
    "print(f\"Taille de X_train : {X_train.shape}\")\n",
    "print(f\"Taille de X_valid : {X_valid.shape}\")\n",
    "print(f\"Taille de y_train : {y_train.shape}\")\n",
    "print(f\"Taille de y_valid : {y_valid.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4cba1a05-6540-49d8-ac8a-df739965955c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rooms</th>\n",
       "      <th>Type</th>\n",
       "      <th>Method</th>\n",
       "      <th>Distance</th>\n",
       "      <th>Postcode</th>\n",
       "      <th>Bedroom2</th>\n",
       "      <th>Bathroom</th>\n",
       "      <th>Car</th>\n",
       "      <th>Landsize</th>\n",
       "      <th>BuildingArea</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>Lattitude</th>\n",
       "      <th>Longtitude</th>\n",
       "      <th>Regionname</th>\n",
       "      <th>Propertycount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12167</th>\n",
       "      <td>1</td>\n",
       "      <td>u</td>\n",
       "      <td>S</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3182.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1940.0</td>\n",
       "      <td>-37.85984</td>\n",
       "      <td>144.9867</td>\n",
       "      <td>Southern Metropolitan</td>\n",
       "      <td>13240.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6524</th>\n",
       "      <td>2</td>\n",
       "      <td>h</td>\n",
       "      <td>SA</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3016.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>193.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-37.85800</td>\n",
       "      <td>144.9005</td>\n",
       "      <td>Western Metropolitan</td>\n",
       "      <td>6380.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8413</th>\n",
       "      <td>3</td>\n",
       "      <td>h</td>\n",
       "      <td>S</td>\n",
       "      <td>12.6</td>\n",
       "      <td>3020.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>555.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-37.79880</td>\n",
       "      <td>144.8220</td>\n",
       "      <td>Western Metropolitan</td>\n",
       "      <td>3755.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2919</th>\n",
       "      <td>3</td>\n",
       "      <td>u</td>\n",
       "      <td>SP</td>\n",
       "      <td>13.0</td>\n",
       "      <td>3046.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>265.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1995.0</td>\n",
       "      <td>-37.70830</td>\n",
       "      <td>144.9158</td>\n",
       "      <td>Northern Metropolitan</td>\n",
       "      <td>8870.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6043</th>\n",
       "      <td>3</td>\n",
       "      <td>h</td>\n",
       "      <td>S</td>\n",
       "      <td>13.3</td>\n",
       "      <td>3020.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>673.0</td>\n",
       "      <td>673.0</td>\n",
       "      <td>1970.0</td>\n",
       "      <td>-37.76230</td>\n",
       "      <td>144.8272</td>\n",
       "      <td>Western Metropolitan</td>\n",
       "      <td>4217.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Rooms Type Method  Distance  Postcode  Bedroom2  Bathroom  Car  \\\n",
       "12167      1    u      S       5.0    3182.0       1.0       1.0  1.0   \n",
       "6524       2    h     SA       8.0    3016.0       2.0       2.0  1.0   \n",
       "8413       3    h      S      12.6    3020.0       3.0       1.0  1.0   \n",
       "2919       3    u     SP      13.0    3046.0       3.0       1.0  1.0   \n",
       "6043       3    h      S      13.3    3020.0       3.0       1.0  2.0   \n",
       "\n",
       "       Landsize  BuildingArea  YearBuilt  Lattitude  Longtitude  \\\n",
       "12167       0.0           NaN     1940.0  -37.85984    144.9867   \n",
       "6524      193.0           NaN        NaN  -37.85800    144.9005   \n",
       "8413      555.0           NaN        NaN  -37.79880    144.8220   \n",
       "2919      265.0           NaN     1995.0  -37.70830    144.9158   \n",
       "6043      673.0         673.0     1970.0  -37.76230    144.8272   \n",
       "\n",
       "                  Regionname  Propertycount  \n",
       "12167  Southern Metropolitan        13240.0  \n",
       "6524    Western Metropolitan         6380.0  \n",
       "8413    Western Metropolitan         3755.0  \n",
       "2919   Northern Metropolitan         8870.0  \n",
       "6043    Western Metropolitan         4217.0  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf4f5304-ad75-453a-bb45-752dea6fecba",
   "metadata": {},
   "source": [
    "Nous construisons le pipeline complet en trois étapes :\n",
    "\n",
    "---\n",
    "\n",
    "### Étape 1 : Définir les étapes de prétraitement\n",
    "Comme un pipeline regroupe les étapes de prétraitement et de modélisation, nous utilisons la classe ColumnTransformer pour regrouper différentes étapes de prétraitement. Le code ci-dessous :\n",
    "\n",
    "- Impute les valeurs manquantes dans les données numériques, et\n",
    "- Impute les valeurs manquantes et applique un encodage one-hot aux données catégoriques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2a8df1f9-aa94-4665-8eea-121b352b79af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Colonnes numériques et catégoriques\n",
    "numerical_cols = ['Rooms', 'Distance', 'Landsize', 'BuildingArea']\n",
    "categorical_cols = ['Type', 'Method', 'Regionname']\n",
    "\n",
    "# Prétraitement des données numériques\n",
    "numerical_transformer = SimpleImputer(strategy='mean')\n",
    "\n",
    "# Prétraitement des données catégoriques\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "# Regrouper le prétraitement des données numériques et catégoriques\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_transformer, numerical_cols),\n",
    "        ('cat', categorical_transformer, categorical_cols)\n",
    "    ])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58044297-80e0-448a-88f9-94f486e22665",
   "metadata": {},
   "source": [
    "### Étape 2 : Définir le modèle\n",
    "Ensuite, nous définissons un modèle de **forêt aléatoire** avec la classe bien connue RandomForestRegressor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "baf1a653-3d9e-4a39-b7ef-776e3bcd764b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "model = RandomForestRegressor(n_estimators=100, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bc8de0c-746c-4307-b4df-52889d82faa3",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Étape 3 : Créer et évaluer le pipeline\n",
    "Enfin, nous utilisons la classe Pipeline pour définir un pipeline qui regroupe les étapes de prétraitement et de modélisation.\n",
    "\n",
    "Points importants :\n",
    "\n",
    "- Avec le pipeline, nous prétraitons les données d'entraînement et ajustons le modèle en une seule ligne de code. (Sans pipeline, il faudrait effectuer l'imputation, l'encodage one-hot et l'entraînement du modèle en étapes séparées, ce qui est particulièrement complexe avec des variables numériques et catégoriques !)\n",
    "- Avec le pipeline, nous fournissons les caractéristiques non traitées dans **X_valid** à la commande **predict()**, et le pipeline prétraite automatiquement les caractéristiques avant de générer des prédictions. (Sans pipeline, il faudrait se souvenir de prétraiter les données de validation avant de faire des prédictions.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0b3b2a1d-6e1c-463a-a2ff-bd205c31958f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 193793.14743097773\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "# Regrouper le prétraitement et la modélisation dans un pipeline\n",
    "my_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('model', model)\n",
    "])\n",
    "\n",
    "# Prétraitement des données d'entraînement, ajustement du modèle\n",
    "my_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Prétraitement des données de validation, génération des prédictions\n",
    "preds = my_pipeline.predict(X_valid)\n",
    "\n",
    "# Évaluer le modèle\n",
    "score = mean_absolute_error(y_valid, preds)\n",
    "print('MAE:', score)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16cf2c87-a573-4634-8ea9-a41e77fd35ac",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Conclusion\n",
    "Les pipelines sont utiles pour organiser le code de **machine learning** et éviter les erreurs. Ils sont particulièrement précieux pour les **workflows** impliquant un prétraitement sophistiqué des données."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46fc1baf-96e6-4e3c-8244-126a34dfbccf",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "# Validation croisée"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "bd402387-dd1d-4e79-a1bc-5a8135dfd445",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "\nAll the 5 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n5 fits failed with the following error:\nTraceback (most recent call last):\n  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1473, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\pipeline.py\", line 469, in fit\n    Xt = self._fit(X, y, routed_params)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\pipeline.py\", line 406, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n                            ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\joblib\\memory.py\", line 312, in __call__\n    return self.func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\pipeline.py\", line 1310, in _fit_transform_one\n    res = transformer.fit_transform(X, y, **params.get(\"fit_transform\", {}))\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 313, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1101, in fit_transform\n    return self.fit(X, y, **fit_params).transform(X)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1473, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\impute\\_base.py\", line 421, in fit\n    X = self._validate_input(X, in_fit=True)\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\impute\\_base.py\", line 348, in _validate_input\n    raise new_ve from None\nValueError: Cannot use mean strategy with non-numeric data:\ncould not convert string to float: 'h'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[43], line 13\u001b[0m\n\u001b[0;32m      7\u001b[0m my_pipeline \u001b[38;5;241m=\u001b[39m Pipeline(steps\u001b[38;5;241m=\u001b[39m[\n\u001b[0;32m      8\u001b[0m     (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpreprocessor\u001b[39m\u001b[38;5;124m'\u001b[39m, SimpleImputer()),\n\u001b[0;32m      9\u001b[0m     (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m'\u001b[39m, RandomForestRegressor(n_estimators\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m))\n\u001b[0;32m     10\u001b[0m ])\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# Obtenir les scores de validation croisée\u001b[39;00m\n\u001b[1;32m---> 13\u001b[0m scores \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m*\u001b[39m cross_val_score(my_pipeline, X, y,\n\u001b[0;32m     14\u001b[0m                               cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m,\n\u001b[0;32m     15\u001b[0m                               scoring\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mneg_mean_absolute_error\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mScores MAE :\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, scores)\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mScore MAE moyen (sur les expériences) :\u001b[39m\u001b[38;5;124m\"\u001b[39m, scores\u001b[38;5;241m.\u001b[39mmean())\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    211\u001b[0m         )\n\u001b[0;32m    212\u001b[0m     ):\n\u001b[1;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    223\u001b[0m     )\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:712\u001b[0m, in \u001b[0;36mcross_val_score\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, params, pre_dispatch, error_score)\u001b[0m\n\u001b[0;32m    709\u001b[0m \u001b[38;5;66;03m# To ensure multimetric format is not supported\u001b[39;00m\n\u001b[0;32m    710\u001b[0m scorer \u001b[38;5;241m=\u001b[39m check_scoring(estimator, scoring\u001b[38;5;241m=\u001b[39mscoring)\n\u001b[1;32m--> 712\u001b[0m cv_results \u001b[38;5;241m=\u001b[39m cross_validate(\n\u001b[0;32m    713\u001b[0m     estimator\u001b[38;5;241m=\u001b[39mestimator,\n\u001b[0;32m    714\u001b[0m     X\u001b[38;5;241m=\u001b[39mX,\n\u001b[0;32m    715\u001b[0m     y\u001b[38;5;241m=\u001b[39my,\n\u001b[0;32m    716\u001b[0m     groups\u001b[38;5;241m=\u001b[39mgroups,\n\u001b[0;32m    717\u001b[0m     scoring\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscore\u001b[39m\u001b[38;5;124m\"\u001b[39m: scorer},\n\u001b[0;32m    718\u001b[0m     cv\u001b[38;5;241m=\u001b[39mcv,\n\u001b[0;32m    719\u001b[0m     n_jobs\u001b[38;5;241m=\u001b[39mn_jobs,\n\u001b[0;32m    720\u001b[0m     verbose\u001b[38;5;241m=\u001b[39mverbose,\n\u001b[0;32m    721\u001b[0m     fit_params\u001b[38;5;241m=\u001b[39mfit_params,\n\u001b[0;32m    722\u001b[0m     params\u001b[38;5;241m=\u001b[39mparams,\n\u001b[0;32m    723\u001b[0m     pre_dispatch\u001b[38;5;241m=\u001b[39mpre_dispatch,\n\u001b[0;32m    724\u001b[0m     error_score\u001b[38;5;241m=\u001b[39merror_score,\n\u001b[0;32m    725\u001b[0m )\n\u001b[0;32m    726\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m cv_results[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_score\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    211\u001b[0m         )\n\u001b[0;32m    212\u001b[0m     ):\n\u001b[1;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    223\u001b[0m     )\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:443\u001b[0m, in \u001b[0;36mcross_validate\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, params, pre_dispatch, return_train_score, return_estimator, return_indices, error_score)\u001b[0m\n\u001b[0;32m    422\u001b[0m parallel \u001b[38;5;241m=\u001b[39m Parallel(n_jobs\u001b[38;5;241m=\u001b[39mn_jobs, verbose\u001b[38;5;241m=\u001b[39mverbose, pre_dispatch\u001b[38;5;241m=\u001b[39mpre_dispatch)\n\u001b[0;32m    423\u001b[0m results \u001b[38;5;241m=\u001b[39m parallel(\n\u001b[0;32m    424\u001b[0m     delayed(_fit_and_score)(\n\u001b[0;32m    425\u001b[0m         clone(estimator),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    440\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m train, test \u001b[38;5;129;01min\u001b[39;00m indices\n\u001b[0;32m    441\u001b[0m )\n\u001b[1;32m--> 443\u001b[0m _warn_or_raise_about_fit_failures(results, error_score)\n\u001b[0;32m    445\u001b[0m \u001b[38;5;66;03m# For callable scoring, the return type is only know after calling. If the\u001b[39;00m\n\u001b[0;32m    446\u001b[0m \u001b[38;5;66;03m# return type is a dictionary, the error scores can now be inserted with\u001b[39;00m\n\u001b[0;32m    447\u001b[0m \u001b[38;5;66;03m# the correct key.\u001b[39;00m\n\u001b[0;32m    448\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(scoring):\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:529\u001b[0m, in \u001b[0;36m_warn_or_raise_about_fit_failures\u001b[1;34m(results, error_score)\u001b[0m\n\u001b[0;32m    522\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m num_failed_fits \u001b[38;5;241m==\u001b[39m num_fits:\n\u001b[0;32m    523\u001b[0m     all_fits_failed_message \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    524\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mAll the \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fits failed.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    525\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIt is very likely that your model is misconfigured.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    526\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou can try to debug the error by setting error_score=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    527\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    528\u001b[0m     )\n\u001b[1;32m--> 529\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(all_fits_failed_message)\n\u001b[0;32m    531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    532\u001b[0m     some_fits_failed_message \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    533\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mnum_failed_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fits failed out of a total of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    534\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe score on these train-test partitions for these parameters\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    538\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    539\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: \nAll the 5 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n5 fits failed with the following error:\nTraceback (most recent call last):\n  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1473, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\pipeline.py\", line 469, in fit\n    Xt = self._fit(X, y, routed_params)\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\pipeline.py\", line 406, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n                            ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\joblib\\memory.py\", line 312, in __call__\n    return self.func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\pipeline.py\", line 1310, in _fit_transform_one\n    res = transformer.fit_transform(X, y, **params.get(\"fit_transform\", {}))\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 313, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1101, in fit_transform\n    return self.fit(X, y, **fit_params).transform(X)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1473, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\impute\\_base.py\", line 421, in fit\n    X = self._validate_input(X, in_fit=True)\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\impute\\_base.py\", line 348, in _validate_input\n    raise new_ve from None\nValueError: Cannot use mean strategy with non-numeric data:\ncould not convert string to float: 'h'\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Pipeline de modélisation\n",
    "my_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', SimpleImputer()),\n",
    "    ('model', RandomForestRegressor(n_estimators=50, random_state=0))\n",
    "])\n",
    "\n",
    "# Obtenir les scores de validation croisée\n",
    "scores = -1 * cross_val_score(my_pipeline, X, y,\n",
    "                              cv=5,\n",
    "                              scoring='neg_mean_absolute_error')\n",
    "\n",
    "print(\"Scores MAE :\\n\", scores)\n",
    "print(\"Score MAE moyen (sur les expériences) :\", scores.mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fb940ab-809b-4870-b288-8c6d61d211d3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-mooc-rr-jupyter]",
   "language": "python",
   "name": "conda-env-.conda-mooc-rr-jupyter-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
