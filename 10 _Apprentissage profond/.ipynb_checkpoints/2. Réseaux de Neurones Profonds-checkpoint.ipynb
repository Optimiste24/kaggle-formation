{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f221aad0-592c-43bb-813b-e0fbc42a410d",
   "metadata": {},
   "source": [
    "# Réseaux de Neurones Profonds  \n",
    "Ajoutez des couches cachées à votre réseau pour découvrir des relations complexes.  \n",
    "\n",
    "## Introduction  \n",
    "Dans cette leçon, nous allons voir comment construire des réseaux de neurones capables d'apprendre les types de relations complexes pour lesquels les réseaux de neurones profonds sont réputés.  \n",
    "\n",
    "L'idée clé ici est la **modularité**, c'est-à-dire construire un réseau complexe à partir d'unités fonctionnelles plus simples. Nous avons déjà vu comment une unité linéaire calcule une fonction linéaire. Maintenant, nous allons voir comment **combiner et modifier ces unités individuelles** pour modéliser des relations plus complexes.  \n",
    "\n",
    "#### Couches  \n",
    "Les réseaux de neurones organisent généralement leurs neurones en couches. Lorsque nous regroupons des unités linéaires partageant un ensemble commun d'entrées, nous obtenons une couche dense.  \n",
    "\n",
    "- *Représentation visuelle : Une couche d'entrée de trois cercles connectée à une couche dense de deux cercles.*  \n",
    "- *Une couche dense de deux unités linéaires recevant deux entrées et un biais.*  \n",
    "\n",
    "Vous pouvez considérer chaque couche d'un réseau de neurones comme effectuant une transformation relativement simple. À travers une pile profonde de couches, un réseau de neurones peut transformer ses entrées de manière de plus en plus complexe. Dans un réseau de neurones bien entraîné, chaque couche est une transformation qui nous rapproche un peu plus de la solution.  \n",
    "\n",
    "#### Plusieurs Types de Couches  \n",
    "Une \"couche\" dans **Keras** est un concept très général. Une couche peut être, essentiellement, n'importe quel type de transformation de données. De nombreuses couches, comme les couches **convolutives et récurrentes**, transforment les données en utilisant des neurones et diffèrent principalement par le schéma de connexions qu'elles forment. D'autres sont utilisées pour l'**ingénierie des caractéristiques** ou simplement pour des **opérations arithmétiques simples**. Il existe tout un monde de couches à découvrir — explorez-les !  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d49b660d-f460-49d8-9313-8855b41040e7",
   "metadata": {},
   "source": [
    "## La Fonction d'Activation  \n",
    "Cependant, il s'avère que deux couches denses sans rien entre elles ne sont pas meilleures qu'une seule couche dense par elle-même. Les couches denses seules ne peuvent jamais nous faire sortir du monde des lignes et des plans. Nous avons besoin de quelque chose de **non linéaire**. Nous avons besoin de fonctions d'activation.  \n",
    "\n",
    "Sans **fonctions d'activation**, les réseaux de neurones ne peuvent apprendre que des relations linéaires. Pour modéliser des courbes, nous devons utiliser des fonctions d'activation.  \n",
    "Une fonction d'activation est simplement une fonction que nous appliquons à chaque sortie d'une couche (ses activations). La plus courante est la **fonction rectifiée (ReLU)** :  \n",
    "**max(0, x)**  \n",
    "\n",
    "*Graphique de la fonction ReLU : une ligne y = x pour x > 0 et y = 0 pour x < 0, formant une forme de charnière comme '_/'*  \n",
    "La fonction ReLU a un graphique qui est une ligne avec la partie négative \"rectifiée\" à zéro. Appliquer cette fonction aux sorties d'un neurone introduit une courbure dans les données, nous éloignant des simples lignes.  \n",
    "\n",
    "Lorsque nous attachons **la fonction ReLU** à une unité linéaire, nous obtenons une unité linéaire rectifiée (ReLU). (Pour cette raison, il est courant d'appeler la fonction ReLU \"fonction d'activation ReLU\".) Appliquer une activation ReLU à une unité linéaire signifie que la sortie devient **max(0, w * x + b)**, que nous pourrions représenter dans un diagramme comme :  \n",
    "\n",
    "*Diagramme d'une seule ReLU : comme une unité linéaire, mais au lieu d'un symbole '+', nous avons maintenant une charnière '_/'*  \n",
    "*Une unité linéaire rectifiée.*  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efa15026-eeba-4f95-86d2-38e3c195084a",
   "metadata": {},
   "source": [
    "#### Empiler des Couches Denses  \n",
    "Maintenant que nous avons une certaine non-linéarité, voyons comment empiler des couches pour obtenir des transformations de données complexes.  \n",
    "\n",
    "*Représentation visuelle : une couche d'entrée, deux couches cachées et une couche linéaire finale.*  \n",
    "Une pile de couches denses forme un réseau \"**entièrement connecté**\".  \n",
    "\n",
    "Les couches avant la couche de sortie sont parfois appelées \"**cachées**\" car nous ne voyons jamais directement leurs sorties.  \n",
    "\n",
    "Remarquez que la dernière couche (la couche de sortie) est une unité linéaire (c'est-à-dire sans fonction d'activation). Cela rend ce réseau approprié pour une tâche de **régression**, où nous essayons de prédire une valeur numérique arbitraire. D'autres tâches (comme la **classification**) pourraient nécessiter une fonction d'activation sur la sortie.  \n",
    "\n",
    "#### Construire des Modèles Séquentiels  \n",
    "Le modèle séquentiel que nous avons utilisé connecte une liste de couches dans l'ordre, de la première à la dernière : la première couche reçoit l'entrée, la dernière couche produit la sortie. Cela crée le modèle illustré ci-dessus :  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "480dfeee-547c-4fbb-8cf4-0504462f8732",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "model = keras.Sequential([\n",
    "    # les couches cachées ReLU\n",
    "    layers.Dense(units=4, activation='relu', input_shape=[2]),\n",
    "    layers.Dense(units=3, activation='relu'),\n",
    "    # la couche de sortie linéaire\n",
    "    layers.Dense(units=1),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59f8a285-8568-4615-9369-c088bfb76310",
   "metadata": {},
   "source": [
    "Assurez-vous de passer toutes les couches ensemble dans une liste, comme `[couche, couche, couche, ...]`, au lieu de les passer comme des arguments séparés. Pour ajouter une fonction d'activation à une couche, il suffit de donner son nom dans l'argument `activation`.  \n",
    "\n",
    "#### À Vous de Jouer  \n",
    "Maintenant, créez un réseau de neurones profond pour le jeu de données Concrete.  \n",
    "\n",
    "Vous avez des questions ou des commentaires ? Visitez le forum de discussion du cours pour discuter avec d'autres apprenants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a6f11a1-e9c7-4948-a90a-a21ddbfaf735",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3872bed9-3dda-4b5d-9864-53c8fb77b7bb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
