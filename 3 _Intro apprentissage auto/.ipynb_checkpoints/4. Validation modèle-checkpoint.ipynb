{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d96d5876-dfd3-4d26-945b-8c7cf830c3c0",
   "metadata": {},
   "source": [
    "# Validation du modèle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32ff7867-76da-4472-804f-83d7300e0414",
   "metadata": {},
   "source": [
    "### Qu'est-ce que la validation de modèle ?\n",
    "La validation d’un modèle est une étape essentielle pour mesurer sa qualité. Elle permet de s'assurer que le modèle fournit des prédictions proches de ce qui se passe réellement. La mesure de la précision prédictive est au cœur de l’amélioration continue des modèles.\n",
    "\n",
    "Une **erreur** courante est d'évaluer un modèle en comparant ses prédictions à partir des **données d'entraînement**. Cela peut donner une impression erronée de la qualité du modèle, car il a déjà \"vu\" ces données. On parle alors d’évaluation **\"in-sample\"**, qui est souvent biaisée."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8231a449-aa94-493c-bdc2-a7cd5b5c9ae9",
   "metadata": {},
   "source": [
    "### L’erreur absolue moyenne (MAE)\n",
    "La **Mean Absolute Error (MAE)** est une métrique simple pour résumer la qualité du modèle. Elle représente la moyenne des écarts absolus entre les valeurs prédites et les valeurs réelles. En termes simples :\n",
    "\n",
    "        En moyenne, nos prédictions sont erronées de X unités.\n",
    "\n",
    "Formule de l'erreur :\n",
    "\n",
    "                    Erreur = Valeur réelle - Valeur prédite\n",
    "\n",
    "La MAE est obtenue en prenant la valeur absolue des erreurs (pour éviter les nombres négatifs), puis en calculant la moyenne."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53521f67-0efb-4f95-ae2f-6133569b07fc",
   "metadata": {},
   "source": [
    "### Le problème des scores \"in-sample\"\n",
    "Les scores \"in-sample\" sont obtenus en évaluant le modèle sur les mêmes données utilisées pour l’entraîner. Cependant, cela peut entraîner des **biais** :\n",
    "\n",
    "Le modèle peut détecter des schémas spécifiques au jeu de données d’entraînement, qui ne se vérifient pas avec de nouvelles données.\n",
    "\n",
    "Cela peut donner des résultats prometteurs en entraînement, mais un modèle peu performant en pratique.\n",
    "\n",
    "Exemple :\n",
    "Si, dans vos données d’entraînement, les maisons avec des portes vertes sont chères, le modèle peut apprendre cette fausse corrélation et donner de mauvaises prédictions sur de nouvelles données."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99f4857b-e3aa-4c73-9ac4-58d424058dd2",
   "metadata": {},
   "source": [
    "### Validation avec des données externes\n",
    "Pour éviter ce **biais**, on utilise des **données de validation** qui n’ont pas été utilisées pour construire le modèle. Cela permet d’évaluer sa performance sur des données nouvelles et non vues.\n",
    "\n",
    "Le découpage des données en deux parties – **données d'entraînement** et **données de validation** – est réalisé avec la fonction **train_test_split** de **Scikit-learn**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "572bf05b-dd3b-4e8c-948d-796db20fc204",
   "metadata": {},
   "source": [
    "### Code : Validation du modèle\n",
    "Voici les étapes principales :\n",
    "\n",
    "1. Diviser les données en données d’entraînement et de validation.\n",
    "2. Entraîner le modèle sur les données d’entraînement.\n",
    "3. Calculer la MAE sur les données de validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "270e6465-6cf0-4c64-b584-ba579b6d4df7",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m mean_absolute_error\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Division des données\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m train_X, val_X, train_y, val_y \u001b[38;5;241m=\u001b[39m train_test_split(X, y, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Définir et entraîner le modèle\u001b[39;00m\n\u001b[0;32m      9\u001b[0m melbourne_model \u001b[38;5;241m=\u001b[39m DecisionTreeRegressor()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "# Division des données\n",
    "train_X, val_X, train_y, val_y = train_test_split(X, y, random_state=0)\n",
    "\n",
    "# Définir et entraîner le modèle\n",
    "melbourne_model = DecisionTreeRegressor()\n",
    "melbourne_model.fit(train_X, train_y)\n",
    "\n",
    "# Prédictions sur les données de validation\n",
    "val_predictions = melbourne_model.predict(val_X)\n",
    "\n",
    "# Calculer la MAE\n",
    "print(mean_absolute_error(val_y, val_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "396da430-8630-490e-a88a-57f967c3bd03",
   "metadata": {},
   "source": [
    "Réponse : 273681.4639552399"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7da3ab9-0d66-4a4d-9734-c9b96e1cada7",
   "metadata": {},
   "source": [
    "#### Résumé :\n",
    "Résultat de la MAE :\n",
    "\n",
    "    Une MAE de 273 681,46 indique une erreur moyenne élevée, suggérant que le modèle nécessite des améliorations pour être précis et utilisable en pratique.\n",
    "\n",
    "random_state=0 :\n",
    "    \n",
    "    Cela garantit que les divisions des données seront reproductibles, rendant vos analyses cohérentes et fiables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbce2258-f016-4ca9-8275-0193a2818422",
   "metadata": {},
   "source": [
    "La **MAE (Mean Absolute Error)** indique que, en moyenne, les prédictions du modèle sont erronées de 273 681,46 unités par rapport aux valeurs réelles.\n",
    "\n",
    "Dans le contexte de **l'immobilier**, si l'unité utilisée est la monnaie locale (par exemple, en euros ou en dollars), cela signifie que :\n",
    "\n",
    "**En moyenne, les prédictions de prix des maisons sont décalées de 273 681,46 par rapport aux prix réels.**\n",
    "\n",
    "### Analyse de la performance**\n",
    "\n",
    "**Performance relative :**\n",
    "\n",
    "**Si la moyenne des prix des maisons dans les données de validation est, par exemple, de 1 000 000, une erreur de 273 681 représente environ 27,37 % du prix moyen.**\n",
    "\n",
    "Cela pourrait être acceptable dans un marché très volatil ou imprécis.\n",
    "Sinon, cela montre que **le modèle est loin d'être suffisamment précis**.\n",
    "\n",
    "**Conséquences pratiques :**\n",
    "\n",
    "Si vous utilisez ce modèle pour prédire des prix immobiliers, une telle erreur peut entraîner des estimations peu fiables, rendant le modèle inadapté pour une prise de décision critique.\n",
    "\n",
    "### Action recommandée :\n",
    "\n",
    "1. Réviser les données d'entraînement : vérifier leur qualité, leur quantité et leur pertinence.\n",
    "2. Tester d'autres modèles ou ajuster les paramètres pour améliorer les performances.\n",
    "3. Ajouter des variables explicatives pertinentes qui pourraient mieux capter les relations dans les données."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d266b243-2618-4eb8-82f5-909fb0fb98b0",
   "metadata": {},
   "source": [
    "#### Interprétation des résultats\n",
    "1. La MAE obtenue avec les données d'entraînement (in-sample) peut être très faible, ce qui donne l'impression d'un modèle performant.\n",
    "2. En revanche, la MAE obtenue avec les données de validation (out-of-sample) est souvent plus élevée. Cela reflète la performance réelle du modèle sur des données non vues."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d1d40d2-fe17-4439-8ad0-efc0201905f2",
   "metadata": {},
   "source": [
    "#### Amélioration du modèle\n",
    "Pour réduire l’erreur et améliorer les prédictions, vous pouvez :\n",
    "\n",
    "1. Expérimenter avec d’autres variables explicatives (features).\n",
    "2. Tester différents types de modèles (exemple : forêts aléatoires, modèles linéaires, etc.).\n",
    "3. Ajuster les hyperparamètres du modèle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6241a390-aac6-424d-9ab5-8fcb35d74d44",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
