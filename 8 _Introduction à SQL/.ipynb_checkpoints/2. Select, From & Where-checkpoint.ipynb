{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "192ec378-a511-4893-9e04-8a5cac60f9ea",
   "metadata": {},
   "source": [
    "# Select, From & Where\n",
    "The foundational compontents for all SQL queries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22254fb0-4652-4220-9e3c-360cef7165f3",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "Maintenant que vous savez comment accéder et examiner un ensemble de données, vous êtes prêt à écrire votre première requête SQL ! Comme vous le verrez bientôt, les requêtes SQL vous aideront à trier un ensemble de données massif, pour récupérer uniquement les informations dont vous avez besoin.\n",
    "\n",
    "Nous commencerons par utiliser les mots-clés **SELECT, FROM et WHERE** pour obtenir des données à partir de colonnes spécifiques en fonction des conditions que vous spécifiez.\n",
    "\n",
    "Pour plus de clarté, nous travaillerons avec un petit ensemble de données imaginaire appelé **pet_records** qui contient une seule table, nommée **pets**.\n",
    "\n",
    "---\n",
    "\n",
    "### SELECT ... FROM\n",
    "La requête SQL la plus basique consiste à sélectionner une seule colonne d'une seule table. Pour ce faire :\n",
    "\n",
    "- Spécifiez la colonne que vous souhaitez après le mot-clé **SELECT**, puis\n",
    "- Spécifiez la table après le mot-clé **FROM**.\n",
    "\n",
    "Par exemple, pour sélectionner la colonne **Name** (de la table **pets** dans la base de données **pet_records** du projet **bigquery-public-data**), notre requête apparaîtrait comme suit :"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1723a775-f44e-4082-932e-846a365e9ea2",
   "metadata": {},
   "source": [
    "```\n",
    "SELECT Name\n",
    "FROM `pets`;\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea7b93b5-e8e0-4b0d-b9b8-422ce0a7743f",
   "metadata": {},
   "source": [
    "*Notez que lorsque vous écrivez une requête SQL, l'argument que nous passons à FROM n'est pas entre guillemets simples (') ou doubles (\"). Il est entre backticks (`).*\n",
    "\n",
    "---\n",
    "\n",
    "### WHERE ...\n",
    "Les ensembles de données BigQuery sont volumineux, donc vous voudrez généralement ne retourner que les lignes répondant à des conditions spécifiques. Vous pouvez le faire en utilisant la clause **WHERE**.\n",
    "\n",
    "La requête ci-dessous retourne les entrées de la colonne **Name** qui se trouvent dans les lignes où la colonne **Animal** contient le texte **'Cat'**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48cb28b7-5beb-47f7-ac54-f7292e376949",
   "metadata": {},
   "source": [
    "```\n",
    "SELECT Name\n",
    "FROM `pets`\n",
    "WHERE Animal = 'Cat';\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "579007c5-4a1d-46f8-abe5-b09f8053619c",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Exemple : Quelles sont toutes les villes américaines dans l'ensemble de données OpenAQ ?\n",
    "Maintenant que vous avez acquis les bases, travaillons sur un exemple avec un ensemble de données réel. Nous utiliserons un ensemble de données **OpenAQ** sur la **qualité de l'air**.\n",
    "\n",
    "Tout d'abord, nous allons configurer tout ce dont nous avons besoin pour exécuter des requêtes et jeter un coup d'œil rapide aux tables présentes dans notre base de données. (Comme vous avez appris à le faire dans le tutoriel précédent, nous avons masqué le code. Mais si vous souhaitez y jeter un œil, il vous suffit de cliquer sur le bouton \"Code\" ci-dessous.)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7cd9af4e-724e-4275-8db6-c8ee093243e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global_air_quality\n"
     ]
    }
   ],
   "source": [
    "from google.cloud import bigquery\n",
    "\n",
    "# Create a \"Client\" object\n",
    "client = bigquery.Client()\n",
    "\n",
    "# Construct a reference to the \"openaq\" dataset\n",
    "dataset_ref = client.dataset(\"openaq\", project=\"bigquery-public-data\")\n",
    "\n",
    "# API request - fetch the dataset\n",
    "dataset = client.get_dataset(dataset_ref)\n",
    "\n",
    "# List all the tables in the \"openaq\" dataset\n",
    "tables = list(client.list_tables(dataset))\n",
    "\n",
    "# Print names of all tables in the dataset (there's only one!)\n",
    "for table in tables:  \n",
    "    print(table.table_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10bbcbfa-1fa6-4576-a9ea-1b1f4991268c",
   "metadata": {},
   "source": [
    "Utilisation de l'intégration BigQuery des ensembles de données publics de Kaggle.\n",
    "\n",
    "L'ensemble de données ne contient qu'une seule table, appelée **global_air_quality**. Nous allons récupérer la table et jeter un coup d'œil aux premières lignes pour voir quel type de données elle contient. (Encore une fois, nous avons masqué le code. Pour y jeter un œil, cliquez sur le bouton \"Code\" ci-dessous.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "afcf378f-0c0e-487a-bc88-a6e5dc8db90e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>location</th>\n",
       "      <th>city</th>\n",
       "      <th>country</th>\n",
       "      <th>pollutant</th>\n",
       "      <th>value</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>unit</th>\n",
       "      <th>source_name</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>averaged_over_in_hours</th>\n",
       "      <th>location_geom</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Borówiec, ul. Drapałka</td>\n",
       "      <td>Borówiec</td>\n",
       "      <td>PL</td>\n",
       "      <td>bc</td>\n",
       "      <td>0.85217</td>\n",
       "      <td>2022-04-28 07:00:00+00:00</td>\n",
       "      <td>µg/m³</td>\n",
       "      <td>GIOS</td>\n",
       "      <td>1.0</td>\n",
       "      <td>52.276794</td>\n",
       "      <td>17.074114</td>\n",
       "      <td>POINT(52.276794 1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Kraków, ul. Bulwarowa</td>\n",
       "      <td>Kraków</td>\n",
       "      <td>PL</td>\n",
       "      <td>bc</td>\n",
       "      <td>0.91284</td>\n",
       "      <td>2022-04-27 23:00:00+00:00</td>\n",
       "      <td>µg/m³</td>\n",
       "      <td>GIOS</td>\n",
       "      <td>1.0</td>\n",
       "      <td>50.069308</td>\n",
       "      <td>20.053492</td>\n",
       "      <td>POINT(50.069308 1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Płock, ul. Reja</td>\n",
       "      <td>Płock</td>\n",
       "      <td>PL</td>\n",
       "      <td>bc</td>\n",
       "      <td>1.41000</td>\n",
       "      <td>2022-03-30 04:00:00+00:00</td>\n",
       "      <td>µg/m³</td>\n",
       "      <td>GIOS</td>\n",
       "      <td>1.0</td>\n",
       "      <td>52.550938</td>\n",
       "      <td>19.709791</td>\n",
       "      <td>POINT(52.550938 1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Elbląg, ul. Bażyńskiego</td>\n",
       "      <td>Elbląg</td>\n",
       "      <td>PL</td>\n",
       "      <td>bc</td>\n",
       "      <td>0.33607</td>\n",
       "      <td>2022-05-03 13:00:00+00:00</td>\n",
       "      <td>µg/m³</td>\n",
       "      <td>GIOS</td>\n",
       "      <td>1.0</td>\n",
       "      <td>54.167847</td>\n",
       "      <td>19.410942</td>\n",
       "      <td>POINT(54.167847 1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Piastów, ul. Pułaskiego</td>\n",
       "      <td>Piastów</td>\n",
       "      <td>PL</td>\n",
       "      <td>bc</td>\n",
       "      <td>0.51000</td>\n",
       "      <td>2022-05-11 05:00:00+00:00</td>\n",
       "      <td>µg/m³</td>\n",
       "      <td>GIOS</td>\n",
       "      <td>1.0</td>\n",
       "      <td>52.191728</td>\n",
       "      <td>20.837489</td>\n",
       "      <td>POINT(52.191728 1)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  location      city country pollutant    value  \\\n",
       "0   Borówiec, ul. Drapałka  Borówiec      PL        bc  0.85217   \n",
       "1    Kraków, ul. Bulwarowa    Kraków      PL        bc  0.91284   \n",
       "2          Płock, ul. Reja     Płock      PL        bc  1.41000   \n",
       "3  Elbląg, ul. Bażyńskiego    Elbląg      PL        bc  0.33607   \n",
       "4  Piastów, ul. Pułaskiego   Piastów      PL        bc  0.51000   \n",
       "\n",
       "                  timestamp   unit source_name  latitude  longitude  \\\n",
       "0 2022-04-28 07:00:00+00:00  µg/m³        GIOS       1.0  52.276794   \n",
       "1 2022-04-27 23:00:00+00:00  µg/m³        GIOS       1.0  50.069308   \n",
       "2 2022-03-30 04:00:00+00:00  µg/m³        GIOS       1.0  52.550938   \n",
       "3 2022-05-03 13:00:00+00:00  µg/m³        GIOS       1.0  54.167847   \n",
       "4 2022-05-11 05:00:00+00:00  µg/m³        GIOS       1.0  52.191728   \n",
       "\n",
       "   averaged_over_in_hours       location_geom  \n",
       "0               17.074114  POINT(52.276794 1)  \n",
       "1               20.053492  POINT(50.069308 1)  \n",
       "2               19.709791  POINT(52.550938 1)  \n",
       "3               19.410942  POINT(54.167847 1)  \n",
       "4               20.837489  POINT(52.191728 1)  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Construct a reference to the \"global_air_quality\" table\n",
    "table_ref = dataset_ref.table(\"global_air_quality\")\n",
    "\n",
    "# API request - fetch the table\n",
    "table = client.get_table(table_ref)\n",
    "\n",
    "# Preview the first five lines of the \"global_air_quality\" table\n",
    "client.list_rows(table, max_results=5).to_dataframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26538b44-013e-4149-8b85-3d0afd413d20",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Tout semble bon ! Alors, mettons ensemble une requête. Disons que nous voulons sélectionner toutes les valeurs de la colonne **city** qui se trouvent dans les lignes où la colonne **country** est **'US'** (pour \"États-Unis\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3f9b1886-d5f2-4b71-bf32-b09f1df70b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Requête pour sélectionner tous les éléments de la colonne \"city\" où la colonne \"country\" est 'US'\n",
    "query = \"\"\"\n",
    "        SELECT city\n",
    "        FROM `bigquery-public-data.openaq.global_air_quality`\n",
    "        WHERE country = 'US'\n",
    "        \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f483572-cab0-48b2-866b-a7e3bdb4c422",
   "metadata": {},
   "source": [
    "Prenez le temps maintenant de vous assurer que cette requête correspond à ce que vous avez appris ci-dessus.\n",
    "\n",
    "---\n",
    "\n",
    "### Soumission de la requête à l'ensemble de données\n",
    "Nous sommes prêts à utiliser cette requête pour obtenir des informations à partir de l'ensemble de données OpenAQ. Comme dans le tutoriel précédent, la première étape consiste à créer un objet **Client**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecfc72cb-9b34-4ed0-afa9-126a9259690f",
   "metadata": {},
   "source": [
    "**Utilisation de l'intégration BigQuery des ensembles de données publics de Kaggle.**\n",
    "\n",
    "Nous commençons par configurer la requête avec la méthode **query()**. Nous exécutons la méthode avec les paramètres par défaut, mais cette méthode nous permet également de spécifier des paramètres plus complexes que vous pouvez consulter dans la documentation. Nous y reviendrons plus tard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "847f5e43-3c02-4a3a-a6bb-828eccc4174a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     city\n",
      "0  HOWARD\n",
      "1  HOWARD\n",
      "2  HOWARD\n",
      "3  HOWARD\n",
      "4  HOWARD\n"
     ]
    }
   ],
   "source": [
    "from google.cloud import bigquery\n",
    "import pandas as pd\n",
    "\n",
    "# Créer un objet \"Client\"\n",
    "client = bigquery.Client()\n",
    "\n",
    "# Requête pour sélectionner toutes les valeurs de la colonne \"city\" où la colonne \"country\" est 'US'\n",
    "query = \"\"\"\n",
    "        SELECT city\n",
    "        FROM `bigquery-public-data.openaq.global_air_quality`\n",
    "        WHERE country = 'US'\n",
    "        \"\"\"\n",
    "\n",
    "# Configurer la requête\n",
    "query_job = client.query(query)\n",
    "\n",
    "# Requête API - exécuter la requête et retourner un DataFrame pandas\n",
    "us_cities = query_job.to_dataframe()\n",
    "\n",
    "# Afficher les 5 premières lignes pour vérifier\n",
    "print(us_cities.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7eb2d56-7d35-4706-bac6-60561ef7ee62",
   "metadata": {},
   "source": [
    "Maintenant, nous avons un DataFrame pandas appelé **us_cities**, que nous pouvons utiliser comme n'importe quel autre DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c617fcc2-5810-4532-b32e-7ae3ce8c64eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "city\n",
       "Phoenix-Mesa-Scottsdale                     39414\n",
       "Los Angeles-Long Beach-Santa Ana            27479\n",
       "Riverside-San Bernardino-Ontario            26887\n",
       "New York-Northern New Jersey-Long Island    25417\n",
       "San Francisco-Oakland-Fremont               22710\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Quelles sont les cinq villes avec le plus de mesures ?\n",
    "us_cities.city.value_counts().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "962295e5-32e8-4c9a-a531-c4ff8e66b9d4",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Plus de requêtes\n",
    "Si vous voulez plusieurs colonnes, vous pouvez les sélectionner en les séparant par une virgule :"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a213a567-7991-4e96-9192-1e6eb26fea7b",
   "metadata": {},
   "source": [
    "```\n",
    "query = \"\"\"\n",
    "        SELECT city, country\n",
    "        FROM `bigquery-public-data.openaq.global_air_quality`\n",
    "        WHERE country = 'US'\n",
    "        \"\"\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b592f38c-51e5-4dcb-810b-98829a2684de",
   "metadata": {},
   "source": [
    "Vous pouvez sélectionner toutes les colonnes avec un * comme ceci :\n",
    "\n",
    "```\n",
    "query = \"\"\"\n",
    "        SELECT *\n",
    "        FROM `bigquery-public-data.openaq.global_air_quality`\n",
    "        WHERE country = 'US'\n",
    "        \"\"\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d14e32a-d5ce-4327-9311-0eb7071cc6a7",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Q&A : Notes sur le formatage\n",
    "Le formatage de la requête SQL peut sembler inhabituel. Si vous avez des questions, vous pouvez les poser dans la section des commentaires en bas de cette page. Voici les réponses à deux questions courantes :\n",
    "\n",
    "**Question : Pourquoi les triples guillemets (\"\"\") ?**\n",
    "\n",
    "**Réponse** : Ils indiquent à Python que tout ce qui se trouve à l'intérieur est une seule chaîne de caractères, même si nous avons des sauts de ligne. Les sauts de ligne ne sont pas nécessaires, mais ils rendent votre requête plus facile à lire.\n",
    "\n",
    "**Question : Faut-il mettre en majuscules SELECT et FROM ?**\n",
    "\n",
    "**Réponse** : Non, SQL ne tient pas compte de la casse. Cependant, il est d'usage de mettre en majuscules les commandes SQL, et cela rend vos requêtes un peu plus faciles à lire."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37419167-394b-4a2d-a122-786297d54a14",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Travailler avec de grands ensembles de données\n",
    "Les ensembles de données **BigQuery** peuvent être énormes. Nous vous permettons de faire beaucoup de calculs gratuitement, mais tout le monde a une certaine limite.\n",
    "\n",
    "Chaque utilisateur **Kaggle peut scanner 5 To tous les 30 jours gratuitement**. Une fois que vous atteignez cette limite, vous devrez attendre qu'elle se réinitialise.\n",
    "\n",
    "Le plus grand ensemble de données actuellement sur Kaggle fait 3 To, donc vous pouvez atteindre votre limite de 30 jours en quelques requêtes si vous n'êtes pas prudent.\n",
    "\n",
    "Ne vous inquiétez pas : nous vous apprendrons comment éviter de scanner trop de données à la fois, afin que vous ne dépassiez pas votre limite.\n",
    "\n",
    "---\n",
    "\n",
    "### Créer un objet QueryJobConfig pour estimer la taille de la requête sans l'exécuter\n",
    "Pour commencer, vous pouvez estimer la taille de n'importe quelle requête avant de l'exécuter. Voici un exemple utilisant l'ensemble de données (très volumineux !) **Hacker News**. Pour voir combien de données une requête va scanner, nous créons un objet **QueryJobConfig** et définissons le paramètre **dry_run** sur True."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "b0f7f1c8-83d3-453f-acad-cfb515cdce3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cette requête va traiter 678222409 octets.\n"
     ]
    }
   ],
   "source": [
    "# Requête pour obtenir la colonne score de chaque ligne où la colonne type a la valeur \"job\"\n",
    "query_score = \"\"\"\n",
    "        SELECT score, title\n",
    "        FROM `bigquery-public-data.hacker_news.full`\n",
    "        WHERE type = \"job\" \n",
    "        \"\"\"\n",
    "\n",
    "# Créer un objet QueryJobConfig pour estimer la taille de la requête sans l'exécuter\n",
    "dry_run_config = bigquery.QueryJobConfig(dry_run=True)\n",
    "\n",
    "# Requête API - exécuter une requête à blanc pour estimer les coûts\n",
    "dry_run_query_job = client.query(query_score, job_config=dry_run_config)\n",
    "\n",
    "print(\"Cette requête va traiter {} octets.\".format(dry_run_query_job.total_bytes_processed))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79f0a32d-0aa9-474e-8954-c5c233026f92",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Limiter la quantité de données 1 Mo\n",
    "Vous pouvez également spécifier un paramètre lors de l'exécution de la requête pour limiter la quantité de données que vous êtes prêt à scanner. Voici un exemple avec une limite basse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "c3ca578b-dffb-40a2-9ec8-78f95970388f",
   "metadata": {},
   "outputs": [
    {
     "ename": "InternalServerError",
     "evalue": "500 Query exceeded limit for bytes billed: 1000000. 678428672 or higher required.; reason: bytesBilledLimitExceeded, message: Query exceeded limit for bytes billed: 1000000. 678428672 or higher required.\n\nLocation: US\nJob ID: ab346933-2ab3-4bf8-9498-0df22937eee8\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInternalServerError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[68], line 9\u001b[0m\n\u001b[0;32m      6\u001b[0m safe_query_job \u001b[38;5;241m=\u001b[39m client\u001b[38;5;241m.\u001b[39mquery(query_score, job_config\u001b[38;5;241m=\u001b[39msafe_config)\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Requête API - essayer d'exécuter la requête et retourner un DataFrame pandas\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m safe_query_job\u001b[38;5;241m.\u001b[39mto_dataframe()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\google\\cloud\\bigquery\\job\\query.py:2057\u001b[0m, in \u001b[0;36mQueryJob.to_dataframe\u001b[1;34m(self, bqstorage_client, dtypes, progress_bar_type, create_bqstorage_client, max_results, geography_as_object, bool_dtype, int_dtype, float_dtype, string_dtype, date_dtype, datetime_dtype, time_dtype, timestamp_dtype, range_date_dtype, range_datetime_dtype, range_timestamp_dtype)\u001b[0m\n\u001b[0;32m   1827\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mto_dataframe\u001b[39m(\n\u001b[0;32m   1828\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1829\u001b[0m     bqstorage_client: Optional[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbigquery_storage.BigQueryReadClient\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1849\u001b[0m     ] \u001b[38;5;241m=\u001b[39m DefaultPandasDTypes\u001b[38;5;241m.\u001b[39mRANGE_TIMESTAMP_DTYPE,\n\u001b[0;32m   1850\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpandas.DataFrame\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m   1851\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return a pandas DataFrame from a QueryJob\u001b[39;00m\n\u001b[0;32m   1852\u001b[0m \n\u001b[0;32m   1853\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2055\u001b[0m \u001b[38;5;124;03m            :mod:`shapely` library cannot be imported.\u001b[39;00m\n\u001b[0;32m   2056\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 2057\u001b[0m     query_result \u001b[38;5;241m=\u001b[39m wait_for_query(\u001b[38;5;28mself\u001b[39m, progress_bar_type, max_results\u001b[38;5;241m=\u001b[39mmax_results)\n\u001b[0;32m   2058\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m query_result\u001b[38;5;241m.\u001b[39mto_dataframe(\n\u001b[0;32m   2059\u001b[0m         bqstorage_client\u001b[38;5;241m=\u001b[39mbqstorage_client,\n\u001b[0;32m   2060\u001b[0m         dtypes\u001b[38;5;241m=\u001b[39mdtypes,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2074\u001b[0m         range_timestamp_dtype\u001b[38;5;241m=\u001b[39mrange_timestamp_dtype,\n\u001b[0;32m   2075\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\google\\cloud\\bigquery\\_tqdm_helpers.py:107\u001b[0m, in \u001b[0;36mwait_for_query\u001b[1;34m(query_job, progress_bar_type, max_results)\u001b[0m\n\u001b[0;32m    103\u001b[0m progress_bar \u001b[38;5;241m=\u001b[39m get_progress_bar(\n\u001b[0;32m    104\u001b[0m     progress_bar_type, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mQuery is running\u001b[39m\u001b[38;5;124m\"\u001b[39m, default_total, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquery\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    105\u001b[0m )\n\u001b[0;32m    106\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m progress_bar \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 107\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m query_job\u001b[38;5;241m.\u001b[39mresult(max_results\u001b[38;5;241m=\u001b[39mmax_results)\n\u001b[0;32m    109\u001b[0m i \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m    110\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\google\\cloud\\bigquery\\job\\query.py:1681\u001b[0m, in \u001b[0;36mQueryJob.result\u001b[1;34m(self, page_size, max_results, retry, timeout, start_index, job_retry)\u001b[0m\n\u001b[0;32m   1676\u001b[0m     remaining_timeout \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1678\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m remaining_timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1679\u001b[0m     \u001b[38;5;66;03m# Since is_job_done() calls jobs.getQueryResults, which is a\u001b[39;00m\n\u001b[0;32m   1680\u001b[0m     \u001b[38;5;66;03m# long-running API, don't delay the next request at all.\u001b[39;00m\n\u001b[1;32m-> 1681\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_job_done():\n\u001b[0;32m   1682\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m   1683\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1684\u001b[0m     \u001b[38;5;66;03m# Use a monotonic clock since we don't actually care about\u001b[39;00m\n\u001b[0;32m   1685\u001b[0m     \u001b[38;5;66;03m# daylight savings or similar, just the elapsed time.\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\google\\api_core\\retry\\retry_unary.py:293\u001b[0m, in \u001b[0;36mRetry.__call__.<locals>.retry_wrapped_func\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    289\u001b[0m target \u001b[38;5;241m=\u001b[39m functools\u001b[38;5;241m.\u001b[39mpartial(func, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    290\u001b[0m sleep_generator \u001b[38;5;241m=\u001b[39m exponential_sleep_generator(\n\u001b[0;32m    291\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_initial, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maximum, multiplier\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_multiplier\n\u001b[0;32m    292\u001b[0m )\n\u001b[1;32m--> 293\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m retry_target(\n\u001b[0;32m    294\u001b[0m     target,\n\u001b[0;32m    295\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_predicate,\n\u001b[0;32m    296\u001b[0m     sleep_generator,\n\u001b[0;32m    297\u001b[0m     timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout,\n\u001b[0;32m    298\u001b[0m     on_error\u001b[38;5;241m=\u001b[39mon_error,\n\u001b[0;32m    299\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\google\\api_core\\retry\\retry_unary.py:153\u001b[0m, in \u001b[0;36mretry_target\u001b[1;34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[0m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m    150\u001b[0m \u001b[38;5;66;03m# This function explicitly must deal with broad exceptions.\u001b[39;00m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m    152\u001b[0m     \u001b[38;5;66;03m# defer to shared logic for handling errors\u001b[39;00m\n\u001b[1;32m--> 153\u001b[0m     _retry_error_helper(\n\u001b[0;32m    154\u001b[0m         exc,\n\u001b[0;32m    155\u001b[0m         deadline,\n\u001b[0;32m    156\u001b[0m         sleep,\n\u001b[0;32m    157\u001b[0m         error_list,\n\u001b[0;32m    158\u001b[0m         predicate,\n\u001b[0;32m    159\u001b[0m         on_error,\n\u001b[0;32m    160\u001b[0m         exception_factory,\n\u001b[0;32m    161\u001b[0m         timeout,\n\u001b[0;32m    162\u001b[0m     )\n\u001b[0;32m    163\u001b[0m     \u001b[38;5;66;03m# if exception not raised, sleep before next attempt\u001b[39;00m\n\u001b[0;32m    164\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(sleep)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\google\\api_core\\retry\\retry_base.py:212\u001b[0m, in \u001b[0;36m_retry_error_helper\u001b[1;34m(exc, deadline, next_sleep, error_list, predicate_fn, on_error_fn, exc_factory_fn, original_timeout)\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m predicate_fn(exc):\n\u001b[0;32m    207\u001b[0m     final_exc, source_exc \u001b[38;5;241m=\u001b[39m exc_factory_fn(\n\u001b[0;32m    208\u001b[0m         error_list,\n\u001b[0;32m    209\u001b[0m         RetryFailureReason\u001b[38;5;241m.\u001b[39mNON_RETRYABLE_ERROR,\n\u001b[0;32m    210\u001b[0m         original_timeout,\n\u001b[0;32m    211\u001b[0m     )\n\u001b[1;32m--> 212\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m final_exc \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msource_exc\u001b[39;00m\n\u001b[0;32m    213\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m on_error_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    214\u001b[0m     on_error_fn(exc)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\google\\api_core\\retry\\retry_unary.py:144\u001b[0m, in \u001b[0;36mretry_target\u001b[1;34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[0m\n\u001b[0;32m    142\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m sleep \u001b[38;5;129;01min\u001b[39;00m sleep_generator:\n\u001b[0;32m    143\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 144\u001b[0m         result \u001b[38;5;241m=\u001b[39m target()\n\u001b[0;32m    145\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39misawaitable(result):\n\u001b[0;32m    146\u001b[0m             warnings\u001b[38;5;241m.\u001b[39mwarn(_ASYNC_RETRY_WARNING)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\google\\cloud\\bigquery\\job\\query.py:1630\u001b[0m, in \u001b[0;36mQueryJob.result.<locals>.is_job_done\u001b[1;34m()\u001b[0m\n\u001b[0;32m   1607\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m job_failed_exception \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1608\u001b[0m     \u001b[38;5;66;03m# Only try to restart the query job if the job failed for\u001b[39;00m\n\u001b[0;32m   1609\u001b[0m     \u001b[38;5;66;03m# a retriable reason. For example, don't restart the query\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1627\u001b[0m     \u001b[38;5;66;03m# into an exception that can be processed by the\u001b[39;00m\n\u001b[0;32m   1628\u001b[0m     \u001b[38;5;66;03m# `job_retry` predicate.\u001b[39;00m\n\u001b[0;32m   1629\u001b[0m     restart_query_job \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m-> 1630\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m job_failed_exception\n\u001b[0;32m   1631\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1632\u001b[0m     \u001b[38;5;66;03m# Make sure that the _query_results are cached so we\u001b[39;00m\n\u001b[0;32m   1633\u001b[0m     \u001b[38;5;66;03m# can return a complete RowIterator.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1639\u001b[0m     \u001b[38;5;66;03m# making any extra API calls if the previous loop\u001b[39;00m\n\u001b[0;32m   1640\u001b[0m     \u001b[38;5;66;03m# iteration fetched the finished job.\u001b[39;00m\n\u001b[0;32m   1641\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reload_query_results(\n\u001b[0;32m   1642\u001b[0m         retry\u001b[38;5;241m=\u001b[39mretry, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mreload_query_results_kwargs\n\u001b[0;32m   1643\u001b[0m     )\n",
      "\u001b[1;31mInternalServerError\u001b[0m: 500 Query exceeded limit for bytes billed: 1000000. 678428672 or higher required.; reason: bytesBilledLimitExceeded, message: Query exceeded limit for bytes billed: 1000000. 678428672 or higher required.\n\nLocation: US\nJob ID: ab346933-2ab3-4bf8-9498-0df22937eee8\n"
     ]
    }
   ],
   "source": [
    "# Exécuter la requête seulement si elle est inférieure à 1 Mo\n",
    "ONE_MB = 1000*1000\n",
    "safe_config = bigquery.QueryJobConfig(maximum_bytes_billed=ONE_MB)\n",
    "\n",
    "# Configurer la requête (ne s'exécutera que si elle est inférieure à 1 Mo)\n",
    "safe_query_job = client.query(query_score, job_config=safe_config)\n",
    "\n",
    "# Requête API - essayer d'exécuter la requête et retourner un DataFrame pandas\n",
    "safe_query_job.to_dataframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "422ae3bd-4086-475e-b513-c78ea7e544e6",
   "metadata": {},
   "source": [
    "---\n",
    "### Augmenter la limite à 1 Go\n",
    "Dans ce cas, la requête a été annulée car la limite de 1 Mo a été dépassée. Cependant, nous pouvons augmenter la limite pour exécuter la requête avec succès !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "836531d7-d04b-404a-828b-1826dfd095e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(1.659159964253798)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Exécuter la requête seulement si elle est inférieure à 1 Go\n",
    "ONE_GB = 1000*1000*1000\n",
    "safe_config = bigquery.QueryJobConfig(maximum_bytes_billed=ONE_GB)\n",
    "\n",
    "# Configurer la requête (ne s'exécutera que si elle est inférieure à 1 Go)\n",
    "safe_query_job = client.query(query_score, job_config=safe_config)\n",
    "\n",
    "# Requête API - essayer d'exécuter la requête et retourner un DataFrame pandas\n",
    "job_post_scores = safe_query_job.to_dataframe()\n",
    "\n",
    "# Afficher le score moyen pour les posts d'emploi\n",
    "job_post_scores.score.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14119abc-26e8-4788-a4d7-0e66bdb7dd71",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73ade915-5dd5-47f2-b904-716ade54a3a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8a2c51d7-2ec7-4b4a-90a1-011b59f40dd4",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# EXERCICE\n",
    "### Introduction\n",
    "Essayez d'écrire quelques instructions **SELECT** par vous-même pour explorer un grand ensemble de données de mesures de **pollution de l'air**.\n",
    "\n",
    "Exécutez la cellule ci-dessous pour configurer le système de feedback."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fb84d0b-fe8b-4f58-bcc3-c05b82beeb49",
   "metadata": {},
   "source": [
    "La cellule de code ci-dessous récupère la table **global_air_quality** de l'ensemble de données **openaq**. Nous prévisualisons également les cinq premières lignes de la table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "67529a8a-e6d1-4ff4-b520-0a2da1b14b88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>location</th>\n",
       "      <th>city</th>\n",
       "      <th>country</th>\n",
       "      <th>pollutant</th>\n",
       "      <th>value</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>unit</th>\n",
       "      <th>source_name</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>averaged_over_in_hours</th>\n",
       "      <th>location_geom</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Borówiec, ul. Drapałka</td>\n",
       "      <td>Borówiec</td>\n",
       "      <td>PL</td>\n",
       "      <td>bc</td>\n",
       "      <td>0.85217</td>\n",
       "      <td>2022-04-28 07:00:00+00:00</td>\n",
       "      <td>µg/m³</td>\n",
       "      <td>GIOS</td>\n",
       "      <td>1.0</td>\n",
       "      <td>52.276794</td>\n",
       "      <td>17.074114</td>\n",
       "      <td>POINT(52.276794 1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Kraków, ul. Bulwarowa</td>\n",
       "      <td>Kraków</td>\n",
       "      <td>PL</td>\n",
       "      <td>bc</td>\n",
       "      <td>0.91284</td>\n",
       "      <td>2022-04-27 23:00:00+00:00</td>\n",
       "      <td>µg/m³</td>\n",
       "      <td>GIOS</td>\n",
       "      <td>1.0</td>\n",
       "      <td>50.069308</td>\n",
       "      <td>20.053492</td>\n",
       "      <td>POINT(50.069308 1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Płock, ul. Reja</td>\n",
       "      <td>Płock</td>\n",
       "      <td>PL</td>\n",
       "      <td>bc</td>\n",
       "      <td>1.41000</td>\n",
       "      <td>2022-03-30 04:00:00+00:00</td>\n",
       "      <td>µg/m³</td>\n",
       "      <td>GIOS</td>\n",
       "      <td>1.0</td>\n",
       "      <td>52.550938</td>\n",
       "      <td>19.709791</td>\n",
       "      <td>POINT(52.550938 1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Elbląg, ul. Bażyńskiego</td>\n",
       "      <td>Elbląg</td>\n",
       "      <td>PL</td>\n",
       "      <td>bc</td>\n",
       "      <td>0.33607</td>\n",
       "      <td>2022-05-03 13:00:00+00:00</td>\n",
       "      <td>µg/m³</td>\n",
       "      <td>GIOS</td>\n",
       "      <td>1.0</td>\n",
       "      <td>54.167847</td>\n",
       "      <td>19.410942</td>\n",
       "      <td>POINT(54.167847 1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Piastów, ul. Pułaskiego</td>\n",
       "      <td>Piastów</td>\n",
       "      <td>PL</td>\n",
       "      <td>bc</td>\n",
       "      <td>0.51000</td>\n",
       "      <td>2022-05-11 05:00:00+00:00</td>\n",
       "      <td>µg/m³</td>\n",
       "      <td>GIOS</td>\n",
       "      <td>1.0</td>\n",
       "      <td>52.191728</td>\n",
       "      <td>20.837489</td>\n",
       "      <td>POINT(52.191728 1)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  location      city country pollutant    value  \\\n",
       "0   Borówiec, ul. Drapałka  Borówiec      PL        bc  0.85217   \n",
       "1    Kraków, ul. Bulwarowa    Kraków      PL        bc  0.91284   \n",
       "2          Płock, ul. Reja     Płock      PL        bc  1.41000   \n",
       "3  Elbląg, ul. Bażyńskiego    Elbląg      PL        bc  0.33607   \n",
       "4  Piastów, ul. Pułaskiego   Piastów      PL        bc  0.51000   \n",
       "\n",
       "                  timestamp   unit source_name  latitude  longitude  \\\n",
       "0 2022-04-28 07:00:00+00:00  µg/m³        GIOS       1.0  52.276794   \n",
       "1 2022-04-27 23:00:00+00:00  µg/m³        GIOS       1.0  50.069308   \n",
       "2 2022-03-30 04:00:00+00:00  µg/m³        GIOS       1.0  52.550938   \n",
       "3 2022-05-03 13:00:00+00:00  µg/m³        GIOS       1.0  54.167847   \n",
       "4 2022-05-11 05:00:00+00:00  µg/m³        GIOS       1.0  52.191728   \n",
       "\n",
       "   averaged_over_in_hours       location_geom  \n",
       "0               17.074114  POINT(52.276794 1)  \n",
       "1               20.053492  POINT(50.069308 1)  \n",
       "2               19.709791  POINT(52.550938 1)  \n",
       "3               19.410942  POINT(54.167847 1)  \n",
       "4               20.837489  POINT(52.191728 1)  "
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from google.cloud import bigquery\n",
    "\n",
    "# Créer un objet \"Client\"\n",
    "client = bigquery.Client()\n",
    "\n",
    "# Construire une référence au dataset \"openaq\"\n",
    "dataset_ref = client.dataset(\"openaq\", project=\"bigquery-public-data\")\n",
    "\n",
    "# Requête API - récupérer le dataset\n",
    "dataset = client.get_dataset(dataset_ref)\n",
    "\n",
    "# Construire une référence à la table \"global_air_quality\"\n",
    "table_ref = dataset_ref.table(\"global_air_quality\")\n",
    "\n",
    "# Requête API - récupérer la table\n",
    "table = client.get_table(table_ref)\n",
    "\n",
    "# Prévisualiser les cinq premières lignes de la table \"global_air_quality\"\n",
    "client.list_rows(table, max_results=5).to_dataframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "049fbccf-3748-4e47-a316-72ce6ed1be29",
   "metadata": {},
   "source": [
    "## Question 1: Unités de mesure\n",
    "Quels pays ont signalé des niveaux de pollution en unités de \"ppm\" ? Dans la cellule de code ci-dessous, définissez **first_query** comme une requête SQL qui extrait les entrées appropriées de la colonne country.\n",
    "\n",
    "Voici un exemple de requête que vous pourriez utiliser :\n",
    "```\n",
    "query = \"\"\"\n",
    "        SELECT city\n",
    "        FROM `bigquery-public-data.openaq.global_air_quality`\n",
    "        WHERE country = 'US'\n",
    "        \"\"\"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "e1fb764d-3321-4e5a-9d64-762725e5d80e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  country\n",
      "0      IL\n",
      "1      IL\n",
      "2      AR\n",
      "3      IL\n",
      "4      AR\n"
     ]
    }
   ],
   "source": [
    "# Requête pour sélectionner les pays avec des unités de \"ppm\"\n",
    "first_query = \"\"\"\n",
    "        SELECT country\n",
    "        FROM `bigquery-public-data.openaq.global_air_quality`\n",
    "        WHERE unit = 'ppm'\n",
    "        \"\"\"\n",
    "\n",
    "# Configurer la requête (annuler la requête si elle utilise trop de quota, avec une limite de 10 Go)\n",
    "safe_config = bigquery.QueryJobConfig(maximum_bytes_billed=10**10)\n",
    "first_query_job = client.query(first_query, job_config=safe_config)\n",
    "\n",
    "# Requête API - exécuter la requête et retourner un DataFrame pandas\n",
    "first_results = first_query_job.to_dataframe()\n",
    "\n",
    "# Voir les premières lignes des résultats\n",
    "print(first_results.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77ca536d-e16c-43ba-8eb2-53104276857e",
   "metadata": {},
   "source": [
    "---\n",
    "## Question 2: Qualité de l'air élevée\n",
    "Quels niveaux de pollution ont été rapportés comme étant exactement 0 ?\n",
    "\n",
    "Définissez zero_pollution_query pour sélectionner toutes les colonnes des lignes où la colonne **value est égale à 0**.\n",
    "Définissez zero_pollution_results comme un DataFrame pandas contenant les résultats de la requête."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "2a38677e-7b5d-4687-93fc-872562572b02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       location      city country pollutant  value  \\\n",
      "0     Zielonka, Bory Tucholskie  Zielonka      PL        bc    0.0   \n",
      "1    Toruń, ul. Przy Kaszowniku     Toruń      PL        bc    0.0   \n",
      "2           Kielce, ul. Targowa    Kielce      PL        bc    0.0   \n",
      "3     Zielonka, Bory Tucholskie  Zielonka      PL        bc    0.0   \n",
      "4  Koszalin, ul. Armii Krajowej  Koszalin      PL        bc    0.0   \n",
      "\n",
      "                  timestamp   unit source_name  latitude  longitude  \\\n",
      "0 2022-04-29 14:00:00+00:00  µg/m³        GIOS       1.0  53.662136   \n",
      "1 2022-04-19 04:00:00+00:00  µg/m³        GIOS       1.0  53.017628   \n",
      "2 2022-05-07 17:00:00+00:00  µg/m³        GIOS       1.0  50.878998   \n",
      "3 2022-05-19 14:00:00+00:00  µg/m³        GIOS       1.0  53.662136   \n",
      "4 2022-05-12 20:00:00+00:00  µg/m³        GIOS       1.0  54.193986   \n",
      "\n",
      "   averaged_over_in_hours       location_geom  \n",
      "0               17.933986  POINT(53.662136 1)  \n",
      "1               18.612808  POINT(53.017628 1)  \n",
      "2               20.633692  POINT(50.878998 1)  \n",
      "3               17.933986  POINT(53.662136 1)  \n",
      "4               16.172544  POINT(54.193986 1)  \n"
     ]
    }
   ],
   "source": [
    "# Requête pour sélectionner toutes les colonnes où les niveaux de pollution sont exactement 0\n",
    "zero_pollution_query = \"\"\"\n",
    "        SELECT *\n",
    "        FROM `bigquery-public-data.openaq.global_air_quality`\n",
    "        WHERE value = 0\n",
    "        \"\"\"\n",
    "\n",
    "# Configurer la requête\n",
    "safe_config = bigquery.QueryJobConfig(maximum_bytes_billed=10**10)\n",
    "query_job = client.query(zero_pollution_query, job_config=safe_config)\n",
    "\n",
    "# Requête API - exécuter la requête et retourner un DataFrame pandas\n",
    "zero_pollution_results = query_job.to_dataframe()\n",
    "\n",
    "print(zero_pollution_results.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d3e30ac-61b4-4d57-9a1e-3aae8e06042b",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Cette requête n'était pas trop compliquée, et elle a récupéré les données que vous vouliez. Mais ces requêtes SELECT ne permettent pas d'organiser les données de manière à répondre aux questions les plus intéressantes. Pour cela, nous aurons besoin de la commande **GROUP BY**.\n",
    "\n",
    "Si vous savez comment utiliser `groupby()` dans pandas, c'est similaire. *Mais BigQuery fonctionne rapidement avec des ensembles de données beaucoup plus grands.*\n",
    "\n",
    "Heureusement, c'est ce que nous allons voir ensuite."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ea082a4-cbe0-4d0c-87b6-4d3946b7d71c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
