{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0ecd8c7b-42c9-4a64-81a2-4b4a07091f9e",
   "metadata": {},
   "source": [
    "# **Le classificateur convolutif**\n",
    "Créez votre premier modèle de vision par ordinateur avec **Keras**.\n",
    " \n",
    "Bienvenue dans le monde de la **Vision par Ordinateur** !  \n",
    "Avez-vous déjà voulu apprendre à un ordinateur à voir ? Dans ce cours, c'est exactement ce que vous ferez !\n",
    "\n",
    "Dans ce cours, vous allez :\n",
    "\n",
    "- Utiliser des réseaux de deep learning modernes pour construire un **classificateur d'images avec Keras**.\n",
    "- Concevoir votre propre réseau convolutif personnalisé avec des blocs réutilisables.\n",
    "- Apprendre les idées fondamentales derrière l'**extraction de caractéristiques visuelles**.\n",
    "- Maîtriser l'**art du transfert learning** pour améliorer vos modèles.\n",
    "- Utiliser l'augmentation de données pour étendre votre jeu de données.\n",
    "\n",
    "Si vous avez suivi le cours d'introduction au deep learning, vous avez déjà toutes les connaissances nécessaires pour réussir.\n",
    "\n",
    "Alors, commençons !"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd968d24-9b45-4424-ac35-3571390bdb15",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Introduction  \n",
    "Ce cours vous présentera les **idées fondamentales de la vision par ordinateur**. Notre objectif est de comprendre comment un réseau neuronal peut \"*comprendre*\" une image naturelle suffisamment bien pour résoudre les mêmes types de problèmes que le système visuel humain peut résoudre.\n",
    "\n",
    "Les réseaux neuronaux les plus performants pour cette tâche sont appelés **réseaux de neurones convolutifs** (parfois appelés **convnet ou CNN**). **La convolution** est l'opération mathématique qui donne aux couches d'un convnet leur structure unique. Dans les leçons futures, vous apprendrez pourquoi cette structure est si efficace pour résoudre les problèmes de vision par ordinateur.\n",
    "\n",
    "Nous appliquerons ces idées au problème de la classification d'images : étant donné une image, pouvons-nous entraîner un ordinateur à nous dire de quoi il s'agit ? Vous avez peut-être déjà vu des applications capables d'identifier une espèce de plante à partir d'une photographie. C'est un classificateur d'images ! Dans ce cours, vous apprendrez à construire des classificateurs d'images aussi puissants que ceux utilisés dans les applications professionnelles.\n",
    "\n",
    "Bien que notre focus soit sur la classification d'images, ce que vous apprendrez dans ce cours est pertinent pour tous les types de problèmes de vision par ordinateur. À la fin, vous serez prêt à passer à des applications plus avancées comme les **réseaux antagonistes génératifs (GAN)** et la **segmentation d'images**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14a4ebb5-953f-4cef-920d-f6fc229b65dd",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Le Classificateur Convolutif  \n",
    "Un convnet utilisé pour la classification d'images se compose de deux parties : **une base convolutive et une tête dense.**\n",
    "\n",
    "- **Les parties d'un convnet** : image, base, tête, classe ; entrée, extraction, classification, sortie.\n",
    "\n",
    "**La base** est utilisée pour extraire les caractéristiques d'une image. Elle est principalement constituée de couches effectuant l'opération de convolution, mais elle inclut souvent d'autres types de couches également. (Vous en apprendrez plus à ce sujet dans la prochaine leçon.)\n",
    "\n",
    "**La tête** est utilisée pour déterminer la classe de l'image. Elle est principalement constituée de couches denses, mais peut inclure d'autres couches comme le dropout.\n",
    "\n",
    "Que voulons-nous dire par **caractéristique visuelle** ? Une caractéristique pourrait être une ligne, une couleur, une texture, une forme, un motif — ou une combinaison complexe de ces éléments.\n",
    "\n",
    "Le processus global ressemble à ceci :\n",
    "\n",
    "L'idée de l'extraction de caractéristiques.  \n",
    "Les caractéristiques réellement extraites sont un peu différentes, mais cela donne une idée."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f44e10d6-770f-41ee-b89d-6152f1e27ee1",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Entraînement du Classificateur\n",
    "L'objectif du réseau pendant l'entraînement est d'apprendre deux choses :\n",
    "\n",
    "1. Quelles caractéristiques extraire d'une image (**base**).\n",
    "2. Quelle classe correspond à quelles caractéristiques (**tête**).\n",
    "\n",
    "Aujourd'hui, les **convnets** sont rarement entraînés à partir de zéro. Plus souvent, nous réutilisons la base d'un modèle pré-entraîné. À cette base pré-entraînée, nous attachons ensuite une tête non entraînée. En d'autres termes, nous réutilisons la partie du réseau qui a déjà appris à extraire des caractéristiques, et nous y attachons de nouvelles couches pour apprendre à classer.\n",
    "\n",
    "Attacher une nouvelle tête à une base entraînée.  \n",
    "Comme la tête est généralement constituée de seulement quelques couches denses, des classificateurs très précis peuvent être créés à partir de relativement peu de données.\n",
    "\n",
    "La réutilisation d'un modèle pré-entraîné est une technique connue sous le nom de **transfert learning**. Elle est si efficace que presque tous les classificateurs d'images aujourd'hui l'utilisent."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24a5d71e-2a1c-444a-a05c-5b288fd8441b",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# **Exemple - Entraîner un Classificateur Convolutif**  \n",
    "Tout au long de ce cours, nous allons créer des classificateurs qui tentent de résoudre le problème suivant : cette image représente-t-elle une Voiture ou un Camion ? Notre jeu de données contient environ 10 000 images de divers automobiles, à peu près moitié voitures et moitié camions.\n",
    "\n",
    "## **Étape 1 - Charger les Données**  \n",
    "La cellule  suivante importera quelques bibliothèques et configurera notre pipeline de données. Nous avons un ensemble d'entraînement appelé *ds_train* et un ensemble de validation appelé *ds_valid*.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fb6e682a-cbe2-49dc-8d44-55a915801576",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "403 - Forbidden - Permission 'datasets.get' was denied\n"
     ]
    }
   ],
   "source": [
    "!kaggle datasets download -d yasshagoro/car-or-truck"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33d56779-7630-4317-b5d6-d96426d36f96",
   "metadata": {},
   "source": [
    "**Décompressez le dataset** :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "faa52a4d-efa7-4bef-8a38-82336008fd4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "with zipfile.ZipFile('car-or-truck.zip', 'r') as zip_ref:\n",
    "    zip_ref.extractall('car-or-truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d3868388-66c1-4ef2-bf6f-81ecbc66721d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports des bibliothèques nécessaires\n",
    "import os, warnings  # Pour gérer les fichiers et les avertissements\n",
    "import matplotlib.pyplot as plt  # Pour la visualisation des données\n",
    "from matplotlib import gridspec  # Pour créer des grilles de graphiques\n",
    "\n",
    "import numpy as np  # Pour les opérations numériques\n",
    "import tensorflow as tf  # Pour le deep learning\n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory  # Pour charger des images depuis un répertoire\n",
    "\n",
    "# Reproductibilité : fonction pour fixer les graines aléatoires\n",
    "def set_seed(seed=31415):\n",
    "    np.random.seed(seed)  # Fixe la graine pour NumPy\n",
    "    tf.random.set_seed(seed)  # Fixe la graine pour TensorFlow\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)  # Fixe la graine pour Python\n",
    "    os.environ['TF_DETERMINISTIC_OPS'] = '1'  # Rend les opérations TensorFlow déterministes\n",
    "set_seed(31415)  # Appel de la fonction pour fixer les graines\n",
    "\n",
    "# Définir les paramètres par défaut de Matplotlib pour une meilleure visualisation\n",
    "plt.rc('figure', autolayout=True)  # Active la mise en page automatique des figures\n",
    "plt.rc('axes', labelweight='bold', labelsize='large',\n",
    "       titleweight='bold', titlesize=18, titlepad=10)  # Style des axes et des titres\n",
    "plt.rc('image', cmap='magma')  # Définit la colormap par défaut pour les images\n",
    "warnings.filterwarnings(\"ignore\")  # Ignore les avertissements pour un affichage plus propre"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20507aa7-e0d0-48d7-954d-b56c38d238db",
   "metadata": {},
   "source": [
    "**Charger les données dans votre notebook**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "573ff5f4-5991-4ea0-8571-454aa42eb9af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5088 files belonging to 2 classes.\n",
      "Found 5051 files belonging to 2 classes.\n",
      "Nombre d'images d'entraînement : 80\n",
      "Nombre d'images de validation : 79\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "\n",
    "# Charger les ensembles d'entraînement et de validation depuis un répertoire local\n",
    "ds_train_ = image_dataset_from_directory(\n",
    "    'car-or-truck/train',  # Chemin vers le dossier d'entraînement\n",
    "    labels='inferred',\n",
    "    label_mode='binary',\n",
    "    image_size=[128, 128],\n",
    "    interpolation='nearest',\n",
    "    batch_size=64,\n",
    "    shuffle=True,\n",
    ")\n",
    "ds_valid_ = image_dataset_from_directory(\n",
    "    'car-or-truck/valid',  # Chemin vers le dossier de validation\n",
    "    labels='inferred',\n",
    "    label_mode='binary',\n",
    "    image_size=[128, 128],\n",
    "    interpolation='nearest',\n",
    "    batch_size=64,\n",
    "    shuffle=False,\n",
    ")\n",
    "\n",
    "# Afficher quelques informations sur les données\n",
    "print(\"Nombre d'images d'entraînement :\", len(ds_train_))\n",
    "print(\"Nombre d'images de validation :\", len(ds_valid_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0f89b186-c5d7-419e-a86b-23904f705864",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipeline de données : fonction pour convertir les images en float32\n",
    "def convert_to_float(image, label):\n",
    "    image = tf.image.convert_image_dtype(image, dtype=tf.float32)  # Convertit les pixels en float32\n",
    "    return image, label  # Retourne l'image et le label\n",
    "\n",
    "# Optimisation du pipeline de données avec AUTOTUNE\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE  # Permet à TensorFlow de choisir automatiquement les paramètres optimaux\n",
    "\n",
    "# Application du pipeline de données à l'ensemble d'entraînement\n",
    "ds_train = (\n",
    "    ds_train_\n",
    "    .map(convert_to_float)  # Convertit les images en float32\n",
    "    .cache()  # Cache les données en mémoire pour accélérer l'entraînement\n",
    "    .prefetch(buffer_size=AUTOTUNE)  # Prépare les données en avance pour éviter les goulots d'étranglement\n",
    ")\n",
    "\n",
    "# Application du pipeline de données à l'ensemble de validation\n",
    "ds_valid = (\n",
    "    ds_valid_\n",
    "    .map(convert_to_float)  # Convertit les images en float32\n",
    "    .cache()  # Cache les données en mémoire pour accélérer la validation\n",
    "    .prefetch(buffer_size=AUTOTUNE)  # Prépare les données en avance pour éviter les goulots d'étranglement\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adf9665f-df60-47df-9b9c-bad18f018ec4",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## **Étape 2 - Définir la Base Pré-entraînée**  \n",
    "Le jeu de données le plus couramment utilisé pour le pré-entraînement est **ImageNet**, un grand ensemble de données contenant de nombreux types d'images naturelles. **Keras** inclut une variété de modèles pré-entraînés sur ImageNet dans son module d'applications. Le modèle pré-entraîné que nous utiliserons s'appelle **VGG16**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "589f3261-5024-4e79-9ca9-5063f9d1a884",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "\u001b[1m58889256/58889256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 0us/step \n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.applications import VGG16\n",
    "\n",
    "# Charger VGG16 pré-entraîné sur ImageNet (par defaut)\n",
    "pretrained_base = VGG16(weights='imagenet', include_top=False, input_shape=(128, 128, 3))\n",
    "pretrained_base.trainable = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80d5ba0e-d35e-4c28-a349-7cdbefddf364",
   "metadata": {},
   "source": [
    "---\n",
    "## **Étape 3 - Attacher la Tête**  \n",
    "Ensuite, nous attachons la tête de classification. Pour cet exemple, nous utiliserons une **couche d'unités cachées** (la première couche Dense) suivie d'une couche pour transformer les sorties en un **score de probabilité** pour la classe 1, *Camion*. La couche **Flatten** transforme les sorties bidimensionnelles de la base en entrées unidimensionnelles nécessaires pour la tête.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "62d8ae4b-1af8-4902-b1ef-87926b741d47",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "model = keras.Sequential([\n",
    "    pretrained_base,\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(6, activation='relu'),\n",
    "    layers.Dense(1, activation='sigmoid'),\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "547ea551-f135-413c-8c0b-e08a406e86da",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## **Étape 4 - Entraîner**  \n",
    "Enfin, entraînons le modèle. Comme il s'agit d'un problème à deux classes, nous utiliserons les versions binaires de la **crossentropy** et de l'**accuracy**. L'optimiseur **Adam** fonctionne généralement bien, nous le choisirons donc également.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abe3896e-a0e1-4d77-bda8-872de018b56b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['binary_accuracy'],\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    ds_train,\n",
    "    validation_data=ds_valid,\n",
    "    epochs=30,\n",
    "    verbose=0,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1787be6-4c5d-471b-9016-508fb2f1efd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da3cedf4-ab78-4b06-9f78-85d568998e04",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Lors de l'entraînement d'un réseau neuronal, il est toujours bon d'examiner les courbes de perte et de métrique. L'objet `history` contient ces informations dans un dictionnaire `history.history`. Nous pouvons utiliser Pandas pour convertir ce dictionnaire en un dataframe et le tracer avec une méthode intégrée.\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "history_frame = pd.DataFrame(history.history)\n",
    "history_frame.loc[:, ['loss', 'val_loss']].plot()\n",
    "history_frame.loc[:, ['binary_accuracy', 'val_binary_accuracy']].plot()\n",
    "```\n",
    "\n",
    "**Conclusion**  \n",
    "Dans cette leçon, nous avons appris la structure d'un classificateur convolutif : une tête pour agir comme un classificateur au-dessus d'une base qui effectue l'extraction de caractéristiques.\n",
    "\n",
    "La tête, essentiellement, est un classificateur ordinaire comme celui que vous avez appris dans le cours d'introduction. Pour les caractéristiques, elle utilise celles extraites par la base. C'est l'idée de base derrière les classificateurs convolutifs : nous pouvons attacher une unité qui effectue l'ingénierie des caractéristiques au classificateur lui-même.\n",
    "\n",
    "C'est l'un des grands avantages des réseaux de neurones profonds par rapport aux modèles d'apprentissage automatique traditionnels : avec la bonne structure de réseau, le réseau de neurones profond peut apprendre à ingénier les caractéristiques dont il a besoin pour résoudre son problème.\n",
    "\n",
    "Pour les prochaines leçons, nous examinerons comment la base convolutive réalise l'extraction de caractéristiques. Ensuite, vous apprendrez à appliquer ces idées et à concevoir vos propres classificateurs.\n",
    "\n",
    "**À vous de jouer !**  \n",
    "Pour l'instant, passez à l'exercice et construisez votre propre classificateur d'images !\n",
    "\n",
    "Vous avez des questions ou des commentaires ? Visitez le forum de discussion du cours pour discuter avec d'autres apprenants."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
